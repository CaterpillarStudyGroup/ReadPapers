# 核心问题是什么？

DDPM的生成速度太慢。

# 相关工作(Chapter 6)

**perform distillation of DDIM teacher models into one-step student models**

*   Eric Luhman and Troy Luhman. Knowledge distillation in iterative generative models for improved sampling speed. arXiv preprint arXiv:2101.02388, 2021.

**few-step sampling, as was the probability flow sampler**

*   DDIM (Song et al., 2021a) was originally shown to be effective for few-step sampling, as was the probability flow sampler (Song et al., 2021c).&#x20;
*   Jolicoeur-Martineau et al. (2021) study fast SDE integrators for reverse diffusion processes
*   Tzen & Raginsky (2019b) study unbiased samplers which may be useful for fast, high quality sampling as well.

**Other work on fast sampling can be viewed as manual or automated methods to adjust samplers or diffusion processes for fast generation.**&#x20;

*   Nichol & Dhariwal (2021); Kong & Ping (2021) describe methods to adjust a discrete time diffusion model trained on many timesteps into models that can sample in few timesteps.&#x20;
*   Watson et al. (2021) describe a dynamic programming algorithm to reduce the number of timesteps for a diffusion model in a way that is optimal for log likelihood.&#x20;
*   Chen et al. (2021); Saharia et al. (2021); Ho et al. (2021) train diffusion models over continuous noise levels and tune samplers post training by adjusting the noise levels of a few-step discrete time reverse diffusion process.&#x20;
*   Their method is effective in highly conditioned settings such as text-to-speech and image super-resolution. San-Roman et al. (2021) train a new network to estimate the noise level of noisy data and show how to use this estimate to speed up sampling.

**Alternative specifications of the diffusion model can also lend themselves to fast sampling,**&#x20;

*   modified forward and reverse processes (Nachmani et al., 2021; Lam et al., 2021)&#x20;
*   &#x20;training diffusion models in latent space (Vahdat et al., 2021).

# 核心贡献是什么？

加速DDPM的生成过程。

1.  we present new parameterizations of diffusion models that provide increased stability when using few sampling steps.&#x20;
2.  we present a method to distill a trained deterministic diffusion sampler.&#x20;

# 大致方法是什么？

![d2a026851eebdc98f0b12efdc0b53a2c\_1\_Figure\_1.png](https://s.readpaper.com/T/2bF23cWDain)

> Figure 1: A visualization of two iterations of our proposed progressive distillation algorithm. A sampler f (z; η), mapping random noise  to samples x in 4 deterministic steps, is distilled into a new sampler f (z; θ) taking only a single step. The original sampler is derived by approximately integrating the probability flow ODE for a learned diffusion model, and distillation can thus be understood as learning to integrate in fewer steps, or amortizing this integration into the new sampler.

✅ 假设有一个 solver，可以根据$x_t$ 预测$x_{t-1}$．\
✅ 调用两次 solver，可以从 $x_t$ 得到$x_{t-2}$，学习这个过程，可以直接得到 2 step 的 solver.\
✅ 前一个 solver 称为 teacher，后一个称为 student.\
✅ student 成为新的 teacher，训练新的 student.

# 有效性

On standard image generation benchmarks like CIFAR-10, ImageNet, and LSUN, we start out with state-of-the-art samplers taking as many as 8192 steps, and are able to distill down to models taking as few as 4 steps without losing much perceptual quality; achieving, for example, a FID of 3.0 on CIFAR-10 in 4 steps.

# 缺陷

| 局限 | 改进点 |
| :-- | :------ |
| In the current work we limited ourselves to setups where the student model has the same architecture and number of parameters as the teacher model: | in future work we hope to relax this constraint and explore settings where the student model is smaller, potentially enabling further gains in test time computational requirements.  |
| | In addition, we hope to move past the generation of images and also explore progressive distillation of diffusion models for different data modalities such as e.g. audio (Chen et al., 2021).|
| | In addition to the proposed distillation procedure, some of our progress was realized through different parameterizations of the diffusion model and its training loss. We expect to see more progress in this direction as the community further explores this model class. |

# 验证

# 启发

1.  The resulting target value $\tilde x(z_t)$ is fully determined given the teacher model and starting point $z_t$, which allows the student model to make a sharp prediction when evaluated at$z_t$. In contrast, the original data point x is not fully determined given $z_t$, since multiple different data points x can produce the same noisy data $z_t$: this means that the original denoising model is predicting a weighted average of possible x values, which produces a blurry prediction.&#x20;
2.  对噪声求L2 loss可以看作是加权平均的重建L2 loss，推导过程见公式9。但在distillation过程中，不适合预测噪声，而应该重建。
3.  In practice, the choice of loss weighting also has to take into account how αt, σt are sampled during training, as this sampling distribution strongly determines the weight the expected loss gives to each signal-to-noise ratio.

# 遗留问题

1.  很多细节看不懂。比如预测x与预测噪声的关系。怎么定义weight?parameterizations of the denoising diffusion model?DDIM?
