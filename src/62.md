# DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation

## 目标

Few-shot finetuning of large models for generating personalized concepts

> &#x2705; 基于目标的多张 reference，输入文本，生成包含目标的图像。要求生成的结果与refernce一致，且具有高质量和多样性：     

![](./assets/D2-32.png) 

> &#x2705; DreamBooth：输入文本和图像，文本中的［V］指代图像，生成新图像。   
> &#x2705; 特点：对预训练的 diffusion model 的权重改变比较大。   


P34   
### Pipeline  

![](./assets/D2-34.png)     
 
> &#x2705; 使用 reference image 微调 model，具体方法为：    
> &#x2705; 输入多张reference image，使用包含特定 identifier 的文本构造 pairdata。目的是对输入图像做 encode。    
> &#x2705; 同时使用用不含 identifer 的图像和文本调练，构造重建 loss 和对抗 loss.目的是生成的多样性及防止过拟合。    

P35   
### DreamBooth Results

![](./assets/D2-35.png)  

> Input Image的基本特征保持住了，但是细节还是有些丢失。比如书包右下角的三个贴图，在每个生成里面都不一样。  
> 用来生成动作照片还是可以的，因为人对动画的细节差异没有那么敏感。例如这只猫。额头上的花纹，在每张图像上都不一样。如果用来生成人，会发明显的差异。  
