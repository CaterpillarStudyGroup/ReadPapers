# Generating time-consistent dynamics with discriminator-guided image diffusion models

## 研究背景与问题

### 要解决的问题

基于T2I模型实现文生视频

### 现有方法及局限性

视频扩散模型 (VDMs) 是目前生成高质量时间动态的最佳技术。但从头训练 VDM 计算成本高昂且复杂。  

### 本文方法及优势

不重新训练或修改现有的大型图像扩散模型（这些模型通常资源丰富且已训练好），而是利用一个额外的时间一致性判别器。该判别器在采样推理阶段（即用训练好的图像模型生成视频序列时）引导生成过程。

1. 在时间一致性方面，新方法达到了与专门训练的 VDM 同等的水平。
2. 新方法能更好地估计其预测的不确定性。
3. 新方法生成的动态更接近真实数据，系统性误差更小。