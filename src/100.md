# MoCLIP: Motion-Aware Fine-Tuning and Distillation of CLIP for Human Motion Generation

## 研究背景与问题

### 要解决的问题

文生动作

### 现有方法及局限性

现有方法通常依赖于基于对比语言-图像预训练（CLIP）的文本编码器，但这些模型在文本-图像对上的训练限制了其对运动中固有时间和运动学结构的理解能力。

### 本文方法及优势

本文提出MoCLIP——一种通过附加运动编码头进行微调的CLIP模型，使用对比学习和约束损失在运动序列上进行训练。通过显式地融合运动感知表征，MoCLIP在保持与现有CLIP框架兼容性的同时提升了运动保真度，并能无缝集成到各类基于CLIP的方法中。  
实验表明，MoCLIP在保持竞争力FID指标的同时提升了Top-1、Top-2和Top-3准确率，实现了更好的文本-运动对齐效果。这些结果凸显了MoCLIP的多功能性和有效性，确立了其作为增强运动生成的稳健框架地位。