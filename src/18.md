# TRAM: Global Trajectory and Motion of 3D Humans from in-the-wild Videos

|缩写|英文|中文|
|---|---|---|
|VIMO|video transformer model|

## 核心问题是什么?

TRAM是一种从in-the-wild视频中重建人类全局轨迹和运动的两阶段方法。  

### 提取相机轨迹

已有方法（16）是通过相机运动 + 人物运动 + 人物运动先验 联合优化出相机scale。作者认为由于人物运动先验是使用室内数据训练得到的，因此不能泛化到室外场景中。  

作者认为仅通过（排除前景干扰的）背景 + 背景语义足以估计出scale。  

### 人物轨迹恢复

已有方法中，单帧方法恢复较准确，但缺少连续性。而时序方法恢复动作不够准确。原因是基于视频的训练成本高且缺少视频数据。  

作者在HMR2.0(预训练的人物模型)上拓展出VIMO模型（增加2个时序transformer），并使用视频数据finetune这个模型。在轨迹信息的相机作为尺度参考系下，回归出人体的运动学身体运动。 

### 效果

通过组合这两个运动，我们实现了世界坐标系中 3D 人体的精确恢复，将全局运动误差比之前的工作减少了 60%。  
https://yufu-wang.github.io/tram4d/

## 核心贡献是什么？

- (i) 我们提出了一种通用方法 TRAM，它可以从野外视频中恢复人体轨迹和运动，比之前的工作有了很大的改进。 
- (ii) 我们证明可以从 SLAM 推断出人体轨迹，并提供技术解决方案，使单目 SLAM 在动态人体存在的情况下具有鲁棒性和公制尺度。 
- (iii) 我们提出了视频变换器模型 VIMO，它建立在大型预训练的基于图像的模型之上，并证明这种可扩展的设计实现了最先进的重建性能。

## 大致方法是什么？

![](./assets/161c67733ee544605c3989dd85fc8aed_4_Figure_2_-1805418559.png)

## 有效

## 缺陷

## 验证

## 启发

## 遗留问题

## 参考材料