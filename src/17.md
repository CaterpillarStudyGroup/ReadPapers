# 3D Gaussian Splatting for Real-Time Radiance Field Rendering

|ç¼©å†™|è‹±æ–‡|ä¸­æ–‡|
|---|---|---|
|SfM|Structure-from-Motion||
|SH|spherical harmonics|çƒè°åŸº|
||covariance matrix|åæ–¹å·®çŸ©é˜µ|
|Nerf|Neural Radiance Field|ç¥ç»è¾å°„åœº|
|GS|Gaussian splatting|é«˜æ–¯æº…å°„|

## æ ¸å¿ƒé—®é¢˜æ˜¯ä»€ä¹ˆ?

### ç°æœ‰æ–¹æ³•åŠé—®é¢˜

Nerfæ–¹æ³•éœ€è¦è®­ç»ƒå’Œæ¸²æŸ“æˆæœ¬é«˜æ˜‚çš„ç¥ç»ç½‘ç»œï¼Œè€Œå…¶åŠ é€Ÿæ–¹æ¡ˆä¼šç‰ºç‰²è´¨é‡æ¥æ¢å–é€Ÿåº¦ã€‚å¯¹äºæ— ç•Œä¸”å®Œæ•´çš„åœºæ™¯ï¼ˆè€Œä¸æ˜¯å­¤ç«‹çš„ç‰©ä½“ï¼‰å’Œ1080påˆ†è¾¨ç‡æ¸²æŸ“ï¼Œå½“å‰æ²¡æœ‰æ–¹æ³•å¯ä»¥å®ç°å®æ—¶æ˜¾ç¤ºé€Ÿç‡ã€‚

### æœ¬æ–‡æ–¹æ³•

é«˜æ–¯æº…å°„æ˜¯ä¸€ç§è¡¨ç¤º 3D åœºæ™¯å’Œæ¸²æŸ“æ–°è§†å›¾çš„æ–¹æ³•ï¼Œå®ƒè¢«è®¤ä¸ºæ˜¯ NeRF ç±»æ¨¡å‹çš„æ›¿ä»£å“ã€‚  
è¿™é¡¹å·¥ä½œæœ€å‡ºåçš„åœ°æ–¹æ˜¯å…¶é«˜æ¸²æŸ“é€Ÿåº¦ã€‚è¿™å½’åŠŸäºä¸‹é¢å°†è¦ä»‹ç»çš„è¡¨ç¤ºæœ¬èº«ï¼Œä»¥åŠä½¿ç”¨è‡ªå®šä¹‰ CUDA å†…æ ¸å®šåˆ¶å®ç°çš„æ¸²æŸ“ç®—æ³•ã€‚    
é¦–å…ˆï¼Œä»ç›¸æœºæ ¡å‡†æœŸé—´äº§ç”Ÿçš„ç¨€ç–ç‚¹å¼€å§‹ï¼Œç”¨ 3D é«˜æ–¯è¡¨ç¤ºåœºæ™¯ï¼Œä¿ç•™è¿ç»­ä½“ç§¯è¾å°„åœºçš„æ‰€éœ€å±æ€§ä»¥è¿›è¡Œåœºæ™¯ä¼˜åŒ–ï¼ŒåŒæ—¶é¿å…åœ¨ç©ºç™½åŒºåŸŸä¸­è¿›è¡Œä¸å¿…è¦çš„è®¡ç®—ï¼›  
å…¶æ¬¡ï¼Œæˆ‘ä»¬å¯¹ 3D é«˜æ–¯è¿›è¡Œäº¤é”™ä¼˜åŒ–/å¯†åº¦æ§åˆ¶ï¼Œç‰¹åˆ«æ˜¯ä¼˜åŒ–å„å‘å¼‚æ€§åæ–¹å·®ä»¥å®ç°åœºæ™¯çš„å‡†ç¡®è¡¨ç¤ºï¼›  
ç¬¬ä¸‰ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§å¿«é€Ÿå¯è§æ€§æ„ŸçŸ¥æ¸²æŸ“ç®—æ³•ï¼Œè¯¥ç®—æ³•æ”¯æŒå„å‘å¼‚æ€§æ³¼æº…ï¼Œæ—¢åŠ é€Ÿè®­ç»ƒåˆå…è®¸å®æ—¶æ¸²æŸ“ã€‚

### æ•ˆæœ

åœ¨å‡ ä¸ªå·²å»ºç«‹çš„æ•°æ®é›†ä¸Šå±•ç¤ºäº†æœ€å…ˆè¿›çš„è§†è§‰è´¨é‡å’Œå®æ—¶æ¸²æŸ“ã€‚

## æ ¸å¿ƒè´¡çŒ®æ˜¯ä»€ä¹ˆï¼Ÿ

- å¼•å…¥å„å‘å¼‚æ€§ 3D é«˜æ–¯ä½œä¸ºè¾å°„åœºçš„é«˜è´¨é‡ã€éç»“æ„åŒ–è¡¨ç¤ºã€‚  
- 3D é«˜æ–¯å±æ€§çš„ä¼˜åŒ–æ–¹æ³•ï¼Œä¸è‡ªé€‚åº”å¯†åº¦æ§åˆ¶äº¤é”™ï¼Œä¸ºæ•è·çš„åœºæ™¯åˆ›å»ºé«˜è´¨é‡è¡¨ç¤ºã€‚  
- å¿«é€Ÿã€å¯å¾®çš„æ¸²æŸ“æ–¹æ³•å¯¹äºå¯è§æ€§æ„ŸçŸ¥çš„ GPUï¼Œå…è®¸å„å‘å¼‚æ€§æ³¼æº…å’Œå¿«é€Ÿåå‘ä¼ æ’­ï¼Œä»¥å®ç°é«˜è´¨é‡çš„æ–°é¢–è§†å›¾åˆæˆã€‚

## å¤§è‡´æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ

![](./assets/90c87fe420b7f068f6ef682c1ee5ed26_4_Figure_2_-1952255684.png)

è¾“å…¥ï¼šä¸€ç»„é™æ€åœºæ™¯çš„å›¾åƒ

1. ç”± SfM æ ¡å‡†çš„ç›¸åº”ç›¸æœºï¼Œä¼šäº§ç”Ÿç¨€ç–ç‚¹äº‘ã€‚  
2. ä»SfMç‚¹äº‘åˆ›å»ºäº†ä¸€ç»„ 3D é«˜æ–¯ï¼ˆç¬¬ 4 èŠ‚ï¼‰ï¼Œç”±ä½ç½®ï¼ˆå‡å€¼ï¼‰ã€åæ–¹å·®çŸ©é˜µå’Œä¸é€æ˜åº¦ ğ›¼ å®šä¹‰è¿™äº›é«˜æ–¯ã€‚  

> è¿™å…è®¸éå¸¸çµæ´»çš„ä¼˜åŒ–æœºåˆ¶ã€‚è¿™ä¼šäº§ç”Ÿ 3D åœºæ™¯çš„ç›¸å½“ç´§å‡‘çš„è¡¨ç¤ºï¼Œéƒ¨åˆ†åŸå› æ˜¯é«˜åº¦**å„å‘å¼‚æ€§çš„ä½“ç§¯ç‰‡å¯ç”¨äºç´§å‡‘åœ°è¡¨ç¤ºç²¾ç»†ç»“æ„**ã€‚

3. è¾å°„åœºçš„æ–¹å‘å¤–è§‚åˆ†é‡ï¼ˆé¢œè‰²ï¼‰é€šè¿‡çƒè°å‡½æ•° (SH) è¡¨ç¤ºã€‚  
4. é€šè¿‡ 3D é«˜æ–¯å‚æ•°çš„ä¸€ç³»åˆ—ä¼˜åŒ–æ­¥éª¤æ¥åˆ›å»ºè¾å°„åœºè¡¨ç¤ºï¼ˆç¬¬ 5 èŠ‚ï¼‰ï¼Œå³ä½ç½®ã€åæ–¹å·®ã€ğ›¼ å’Œ SH ç³»æ•°ä¸é«˜æ–¯å¯†åº¦è‡ªé€‚åº”æ§åˆ¶çš„æ“ä½œäº¤ç»‡åœ¨ä¸€èµ·ã€‚
5. åŸºäºå›¾å—çš„å…‰æ …åŒ–å™¨ï¼ˆæ•ˆç‡çš„å…³é”®ï¼‰ï¼ˆç¬¬ 6 èŠ‚ï¼‰ï¼Œè®©å„å‘å¼‚æ€§å›¾å—çš„ğ›¼æ··åˆï¼Œé€šè¿‡å¿«é€Ÿæ’åºè¡¨ç¤ºå¯è§æ€§é¡ºåºã€‚  
> å¿«é€Ÿå…‰æ …åŒ–å™¨è¿˜åŒ…æ‹¬é€šè¿‡è·Ÿè¸ªç´¯ç§¯çš„ ğ›¼ å€¼è¿›è¡Œå¿«é€Ÿå‘åä¼ é€’ï¼Œå¹¶ä¸”å¯¹å¯ä»¥æ¥æ”¶æ¢¯åº¦çš„é«˜æ–¯æ•°é‡æ²¡æœ‰é™åˆ¶ã€‚

### å¯å¾® 3D é«˜æ–¯Splatting

è¾“å…¥ï¼šæ²¡æœ‰æ³•çº¿ä¿¡æ¯çš„ç¨€ç– (SfM) ç‚¹é›†  
è¾“å‡ºï¼šå…è®¸é«˜è´¨é‡æ–°è§†è§’åˆæˆçš„åœºæ™¯è¡¨ç¤ºï¼Œå³ä¸€ç»„ 3D é«˜æ–¯ã€‚  

#### è¡¨ç¤º

3D ä¸–ç•Œç”±ä¸€ç»„ 3D ç‚¹è¡¨ç¤ºï¼Œå®é™…ä¸Šæœ‰æ•°ç™¾ä¸‡ä¸ª 3D ç‚¹ï¼Œæ•°é‡å¤§çº¦ä¸º 50 ä¸‡åˆ° 500 ä¸‡ã€‚æ¯ä¸ªç‚¹éƒ½æ˜¯ä¸€ä¸ª 3D é«˜æ–¯ï¼Œå…·æœ‰è‡ªå·±ç‹¬ç‰¹çš„å‚æ•°ï¼Œè¿™äº›å‚æ•°é’ˆå¯¹æ¯ä¸ªåœºæ™¯è¿›è¡Œæ‹Ÿåˆï¼Œä»¥ä¾¿è¯¥**åœºæ™¯çš„æ¸²æŸ“ä¸å·²çŸ¥çš„æ•°æ®é›†å›¾åƒç´§å¯†åŒ¹é…**ã€‚  

æ¯ä¸ª 3D é«˜æ–¯çš„å‚æ•°å¦‚ä¸‹ï¼š
- å‡å€¼ Î¼ï¼Œ å¯è§£é‡Šä¸ºä½ç½® xã€yã€zï¼›
- åæ–¹å·® Î£ï¼›
- ä¸é€æ˜åº¦ Ïƒ(ğ›¼)ï¼Œåº”ç”¨ sigmoid å‡½æ•°å°†å‚æ•°æ˜ å°„åˆ° [0, 1] åŒºé—´ï¼›
- é¢œè‰²å‚æ•°ï¼Œ(Rã€Gã€B) çš„ 3 ä¸ªå€¼æˆ–çƒè°å‡½æ•° (SH) ç³»æ•°ã€‚

é€‰æ‹©3Dé«˜æ–¯ä½œä¸ºåœºæ™¯è¡¨ç¤ºæ˜¯å› ä¸ºï¼š  
1. å…·æœ‰å¯å¾®åˆ†ä½“ç§¯è¡¨ç¤ºçš„å±æ€§  
2. éç»“æ„åŒ–å’Œæ˜¾å¼çš„ï¼Œä»¥å…è®¸éå¸¸å¿«é€Ÿçš„æ¸²æŸ“
3. å¯ä»¥è½»æ¾æŠ•å½±åˆ° 2D splatsï¼Œä»è€Œå®ç°å¿«é€Ÿğ›¼æ··åˆæ¸²æŸ“

> ä¹‹å‰çš„ç±»ä¼¼å·¥ä½œä½¿ç”¨å¸¦æ³•çº¿ä¿¡æ¯çš„2Då¹³é¢åœ†ã€‚ä½†SfMæœ‰æ—¶æ˜¯éš¾ä»¥ä¼°è®¡æ¯”è¾ƒå‡†ç¡®çš„æ³•çº¿ä¿¡æ¯ï¼Œå› æ­¤ç»™è¿™äº›æ–¹æ³•å¸¦æ¥çš„å›°éš¾ã€‚  

æœ¬æ–‡ä½¿ç”¨çš„3Dé«˜æ–¯ï¼Œç”±ä¸–ç•Œåæ ‡ç³»ä¸‹çš„3Dåæ–¹å·®çŸ©é˜µå’Œä¸­å¿ƒä½ç½®æ¥æè¿°ã€‚ä¸éœ€è¦åŒ…å«æ³•çº¿ä¿¡æ¯ã€‚  

##### åæ–¹å·®çŸ©é˜µ

åæ–¹å·®æ˜¯å„å‘å¼‚æ€§çš„ï¼Œè¿™æ„å‘³ç€ 3D ç‚¹å¯ä»¥æ˜¯æ²¿ç©ºé—´ä¸­ä»»æ„æ–¹å‘æ—‹è½¬å’Œæ‹‰ä¼¸çš„æ¤­åœ†ä½“ã€‚éœ€è¦ç”¨ 9 ä¸ªå‚æ•°æ¥è¡¨ç¤ºåæ–¹å·®çŸ©é˜µã€‚  

> è¿™ç§å„å‘å¼‚æ€§åæ–¹å·®çš„è¡¨ç¤ºï¼ˆé€‚åˆä¼˜åŒ–ï¼‰å…è®¸æˆ‘ä»¬ä¼˜åŒ– 3D é«˜æ–¯ä»¥é€‚åº”æ•è·åœºæ™¯ä¸­ä¸åŒå½¢çŠ¶çš„å‡ ä½•å½¢çŠ¶ï¼Œä»è€Œäº§ç”Ÿç›¸å½“ç´§å‡‘çš„è¡¨ç¤ºã€‚å›¾ 3 è¯´æ˜äº†è¿™ç§æƒ…å†µã€‚

åæ–¹å·®çŸ©é˜µæ˜¯éœ€è¦è¢«ä¼˜åŒ–çš„å‚æ•°ä¹‹ä¸€ï¼Œä½†æ˜¯ä¸èƒ½ç›´æ¥ä¼˜åŒ–è¿™æ ·çš„åæ–¹å·®çŸ©é˜µã€‚  
**ä¼˜åŒ–è¿‡ç¨‹ä¸­å¿…é¡»ä¿è¯åæ–¹å·®çŸ©é˜µæ˜¯åŠæ­£å®šçš„**ï¼Œä½†æ¢¯åº¦ä¸‹é™çš„ä¼˜åŒ–æ–¹æ³•ä¼šç ´ååæ–¹å·®çŸ©é˜µçš„çš„åŠæ­£å®šæ€§ã€‚å› æ­¤ï¼ŒæŠŠåæ–¹å·®çŸ©é˜µåˆ†è§£ä¸ºï¼š    
  
$$
\Sigma = RSS^\top R^\top
$$

è¿™ç§å› å¼åˆ†è§£ç§°ä¸ºåæ–¹å·®çŸ©é˜µçš„ç‰¹å¾åˆ†è§£ï¼Œå…¶ä¸­ï¼š
- S æ˜¯ä¸€ä¸ªå¯¹è§’ç¼©æ”¾çŸ©é˜µï¼Œå…·æœ‰ 3 ä¸ªç¼©æ”¾å‚æ•°ï¼›
- R æ˜¯ä¸€ä¸ª 3x3 æ—‹è½¬çŸ©é˜µï¼Œç”¨ 4 ä¸ªå››å…ƒæ•°è¡¨ç¤ºã€‚

Så’ŒRåˆ†åˆ«å­˜å‚¨å’Œä¼˜åŒ–ã€‚

```python
def strip_symmetric(L):
    uncertainty = torch.zeros((L.shape[0], 6), dtype=torch.float, device="cuda")

    uncertainty[:, 0] = L[:, 0, 0]
    uncertainty[:, 1] = L[:, 0, 1]
    uncertainty[:, 2] = L[:, 0, 2]
    uncertainty[:, 3] = L[:, 1, 1]
    uncertainty[:, 4] = L[:, 1, 2]
    uncertainty[:, 5] = L[:, 2, 2]
    return uncertainty

def build_scaling_rotation(s, r):
    L = torch.zeros((s.shape[0], 3, 3), dtype=torch.float, device="cuda")
    R = build_rotation(r)

    L[:,0,0] = s[:,0]
    L[:,1,1] = s[:,1]
    L[:,2,2] = s[:,2]

    L = R @ L
    return L

# scalingå’Œrotationæ˜¯ä¼˜åŒ–å¥½çš„Så’ŒR
def build_covariance_from_scaling_rotation(scaling, scaling_modifier, rotation):
    # æ„é€ ä¸€ä¸ªåŒ…å«ç¼©æ”¾scaleå’Œæ—‹è½¬rotationçš„å˜æ¢çŸ©é˜µ
    L = build_scaling_rotation(scaling_modifier * scaling, rotation)
    actual_covariance = L @ L.transpose(1, 2)
    # ç”±äºactual_covarianceæ˜¯å¯¹ç§°çŸ©é˜µï¼Œåªéœ€è¦å­˜ä¸€åŠå°±å¯ä»¥äº†ï¼Œå‚æ•°å‡å°‘åˆ°6
    symm = strip_symmetric(actual_covariance)
    return symm
```

æ¸²æŸ“æ—¶ï¼ŒæŠŠç¼©æ”¾å’Œæ—‹è½¬å†åˆæˆåæ–¹å·®çŸ©é˜µï¼š  

```c++
// Forward method for converting scale and rotation properties of each
// Gaussian to a 3D covariance matrix in world space. Also takes care
// of quaternion normalization.
__device__ void computeCov3D(
	const glm::vec3 scale, // è¡¨ç¤ºç¼©æ”¾çš„ä¸‰ç»´å‘é‡
	float mod, // å¯¹åº”gaussian_renderer/__init__.pyä¸­çš„scaling_modifier
	const glm::vec4 rot, // è¡¨ç¤ºæ—‹è½¬çš„å››å…ƒæ•°
	float* cov3D) // ç»“æœï¼šä¸‰ç»´åæ–¹å·®çŸ©é˜µ
{
	// Create scaling matrix
	glm::mat3 S = glm::mat3(1.0f);
	S[0][0] = mod * scale.x;
	S[1][1] = mod * scale.y;
	S[2][2] = mod * scale.z;

	// Normalize quaternion to get valid rotation
	glm::vec4 q = rot;// / glm::length(rot);
	float r = q.x;
	float x = q.y;
	float y = q.z;
	float z = q.w;

	// Compute rotation matrix from quaternion
	glm::mat3 R = glm::mat3(
		1.f - 2.f * (y * y + z * z), 2.f * (x * y - r * z), 2.f * (x * z + r * y),
		2.f * (x * y + r * z), 1.f - 2.f * (x * x + z * z), 2.f * (y * z - r * x),
		2.f * (x * z - r * y), 2.f * (y * z + r * x), 1.f - 2.f * (x * x + y * y)
	);

	glm::mat3 M = S * R;

	// Compute 3D world covariance matrix Sigma
	glm::mat3 Sigma = glm::transpose(M) * M;

	// Covariance is symmetric, only store upper right
	cov3D[0] = Sigma[0][0];
	cov3D[1] = Sigma[0][1];
	cov3D[2] = Sigma[0][2];
	cov3D[3] = Sigma[1][1];
	cov3D[4] = Sigma[1][2];
	cov3D[5] = Sigma[2][2];
}
```

##### é¢œè‰²å‚æ•°

é¢œè‰²å‚æ•°å¯ä»¥ç”¨3ä¸ªRGBå€¼æˆ–ä¸€ç»„SHç³»æ•°æ¥è¡¨ç¤ºã€‚  

ä¸éœ€è¦è§†è§’ä¾èµ–ç‰¹æ€§æ—¶ï¼Œå¯ä»¥è¿›è¡Œç®€åŒ–ï¼Œé€‰æ‹©ç”¨ 3 ä¸ª RGB å€¼è¡¨ç¤ºé¢œè‰²ã€‚  

è§†è§’ä¾èµ–æ€§æ˜¯ä¸€ç§å¾ˆå¥½çš„ç‰¹æ€§ï¼Œå®ƒå¯ä»¥æé«˜æ¸²æŸ“è´¨é‡ï¼Œå› ä¸ºå®ƒå…è®¸æ¨¡å‹è¡¨ç¤ºéæœ—ä¼¯æ•ˆåº”ï¼Œä¾‹å¦‚é‡‘å±è¡¨é¢çš„é•œé¢åå°„ã€‚  

è§†è§’ç›¸å…³çš„é¢œè‰²å‚æ•°ï¼Œåˆ™éœ€è¦ä½¿ç”¨SHç³»æ•°è¡¨ç¤ºé¢œè‰²ã€‚  
SHæ˜¯ä¸€ç»„å®šä¹‰åœ¨çƒè¡¨é¢çš„æ­£äº¤åŸºï¼Œæ¯ä¸ªå®šä¹‰åœ¨çƒé¢ä¸Šçš„å‡½æ•°éƒ½å¯ä»¥é€šè¿‡SHæ¥è¡¨è¾¾ã€‚

![](./assets/1_bKNS_UyAOGcQvew-b-pciQ.webp)

å®šä¹‰SHåŸºçš„è‡ªç”±åº¦â„“_max å†…ï¼Œå¹¶å‡è®¾æ¯ç§é¢œè‰²ï¼ˆçº¢è‰²ã€ç»¿è‰²å’Œè“è‰²ï¼‰éƒ½æ˜¯å‰ â„“_max ä¸ª SH å‡½æ•°çš„çº¿æ€§ç»„åˆã€‚å¯¹äºæ¯ä¸ª 3D é«˜æ–¯ï¼Œé€šè¿‡å­¦ä¹ å…¶æ­£ç¡®çš„ç³»æ•°ï¼Œä½¿å¾—å½“æˆ‘ä»¬ä»æŸä¸ªæ–¹å‘çœ‹è¿™ä¸ª 3D ç‚¹æ—¶ï¼Œå¾—åˆ°æœ€æ¥è¿‘çœŸå®çš„é¢œè‰²ã€‚

```python
# degï¼šçƒååŸºçš„ä¸ªæ•°
# shï¼šä¼˜åŒ–å‡ºçš„SHç³»æ•°
# dirsï¼šç›¸æœºæŒ‡å‘é«˜æ–¯çƒå¿ƒçš„è§†çº¿æ–¹å‘
def eval_sh(deg, sh, dirs):
    """
    Evaluate spherical harmonics at unit directions
    using hardcoded SH polynomials.
    Works with torch/np/jnp.
    ... Can be 0 or more batch dimensions.
    Args:
        deg: int SH deg. Currently, 0-3 supported
        sh: jnp.ndarray SH coeffs [..., C, (deg + 1) ** 2]
        dirs: jnp.ndarray unit directions [..., 3]
    Returns:
        [..., C]
    """
    assert deg <= 4 and deg >= 0
    # ç¬¬lå±‚çš„çƒååŸºéœ€è¦2*i+1ä¸ªç³»æ•°ï¼Œ[0,l]å±‚çƒååŸºå…±éœ€è¦(l+1)**2ä¸ªç³»æ•°
    coeff = (deg + 1) ** 2
    assert sh.shape[-1] >= coeff

    # C0,C1,C2,C3,C4æ˜¯æå‰å®šä¹‰å¥½çš„çƒååŸºï¼Œæ˜¯å®šå€¼ï¼Œä¸éœ€è¦è¢«ä¼˜åŒ–
    result = C0 * sh[..., 0]
    if deg > 0:
        x, y, z = dirs[..., 0:1], dirs[..., 1:2], dirs[..., 2:3]
        result = (result -
                C1 * y * sh[..., 1] +
                C1 * z * sh[..., 2] -
                C1 * x * sh[..., 3])

        if deg > 1:
            xx, yy, zz = x * x, y * y, z * z
            xy, yz, xz = x * y, y * z, x * z
            result = (result +
                    C2[0] * xy * sh[..., 4] +
                    C2[1] * yz * sh[..., 5] +
                    C2[2] * (2.0 * zz - xx - yy) * sh[..., 6] +
                    C2[3] * xz * sh[..., 7] +
                    C2[4] * (xx - yy) * sh[..., 8])

            if deg > 2:
                result = (result +
                C3[0] * y * (3 * xx - yy) * sh[..., 9] +
                C3[1] * xy * z * sh[..., 10] +
                C3[2] * y * (4 * zz - xx - yy)* sh[..., 11] +
                C3[3] * z * (2 * zz - 3 * xx - 3 * yy) * sh[..., 12] +
                C3[4] * x * (4 * zz - xx - yy) * sh[..., 13] +
                C3[5] * z * (xx - yy) * sh[..., 14] +
                C3[6] * x * (xx - 3 * yy) * sh[..., 15])

                if deg > 3:
                    result = (result + C4[0] * xy * (xx - yy) * sh[..., 16] +
                            C4[1] * yz * (3 * xx - yy) * sh[..., 17] +
                            C4[2] * xy * (7 * zz - 1) * sh[..., 18] +
                            C4[3] * yz * (7 * zz - 3) * sh[..., 19] +
                            C4[4] * (zz * (35 * zz - 30) + 3) * sh[..., 20] +
                            C4[5] * xz * (7 * zz - 3) * sh[..., 21] +
                            C4[6] * (xx - yy) * (7 * zz - 1) * sh[..., 22] +
                            C4[7] * xz * (xx - 3 * yy) * sh[..., 23] +
                            C4[8] * (xx * (xx - 3 * yy) - yy * (3 * xx - yy)) * sh[..., 24])
    return result
```

#### æ¸²æŸ“

##### ä¸€ä¸ªé«˜æ–¯çƒå¯¹ä¸€ä¸ªåƒç´ ç‚¹çš„å½±å“

ç¬¬iä¸ª3Dé«˜æ–¯çƒå¯¹3Dä¸­ä»»æ„ä¸€ç‚¹pçš„å½±å“å®šä¹‰å¦‚ä¸‹ï¼š

![](./assets/1_JGh_0y3ICNuA6IcnbdnvdA.gif)

> è¿™ä¸ªæ–¹ç¨‹å’Œå¤šå…ƒæ­£æ€åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°çš„åŒºåˆ«åœ¨äºï¼Œæ²¡æœ‰åæ–¹å·®å½’ä¸€åŒ–é¡¹ï¼Œä¸”ä½¿ç”¨ç”¨ä¸é€æ˜åº¦æ¥åŠ æƒã€‚
> é«˜æ–¯çš„å¦™å¤„åœ¨äºæ¯ä¸ªç‚¹éƒ½æœ‰åŒé‡å½±å“ã€‚ä¸€æ–¹é¢ï¼Œæ ¹æ®å…¶åæ–¹å·®ï¼Œæ¯ä¸ªç‚¹å®é™…ä¸Šä»£è¡¨äº†ç©ºé—´ä¸­æ¥è¿‘å…¶å‡å€¼çš„æœ‰é™åŒºåŸŸã€‚å¦ä¸€æ–¹é¢ï¼Œå®ƒå…·æœ‰ç†è®ºä¸Šæ— é™çš„èŒƒå›´ï¼Œè¿™æ„å‘³ç€æ¯ä¸ªé«˜æ–¯å‡½æ•°éƒ½å®šä¹‰åœ¨æ•´ä¸ª 3D ç©ºé—´ä¸­ï¼Œå¹¶ä¸”å¯ä»¥é’ˆå¯¹ä»»ä½•ç‚¹è¿›è¡Œè¯„ä¼°ã€‚è¿™å¾ˆæ£’ï¼Œå› ä¸ºåœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œå®ƒå…è®¸æ¢¯åº¦ä»è¿œè·ç¦»æµåŠ¨ã€‚â´

##### æ‰€æœ‰é«˜æ–¯çƒå¯¹ä¸€ä¸ªåƒç´ çš„å½±å“

NeRF å’Œé«˜æ–¯æº…å°„ä½¿ç”¨ç›¸åŒçš„é€ç‚¹ ğ›¼ æ··åˆçš„å›¾åƒå½¢æˆæ¨¡å‹ã€‚  

|Nerf|3D GS|
|---|---|
|![](./assets/1_dovqzRKuf4Sf324f-_Smjg.webp)|![](./assets/1_op2L1Cv4fCMHlYFLnbG0tw.webp)|

Nerfçš„å…¬å¼å’Œ3D GSçš„å…¬å¼å‡ ä¹å®Œå…¨ç›¸åŒã€‚å”¯ä¸€çš„åŒºåˆ«åœ¨äºä¸¤è€…ä¹‹é—´å¦‚ä½•è®¡ç®— ğ›¼ã€‚åœ¨é«˜æ–¯æº…å°„ä¸­ï¼Œæ¯ä¸ªåƒç´ çš„èšåˆéƒ½æ˜¯é€šè¿‡æŠ•å½±äºŒç»´é«˜æ–¯çš„æœ‰åºåˆ—è¡¨çš„è´¡çŒ®è¿›è¡Œçš„ã€‚

> è¿™ç§å¾®å°çš„å·®å¼‚åœ¨å®è·µä¸­å˜å¾—æä¸ºé‡è¦ï¼Œå¹¶å¯¼è‡´æ¸²æŸ“é€Ÿåº¦æˆªç„¶ä¸åŒã€‚äº‹å®ä¸Šï¼Œè¿™æ˜¯é«˜æ–¯æº…å°„å®æ—¶æ€§èƒ½çš„åŸºç¡€ã€‚

##### åæ ‡ç³»è½¬æ¢

3D GSå…¬å¼ä¸­çš„\\(f^{2D}\\) æ˜¯ f(p) åœ¨ 2D ä¸Šçš„æŠ•å½±ã€‚3D ç‚¹åŠå…¶æŠ•å½±éƒ½æ˜¯å¤šå…ƒé«˜æ–¯å‡½æ•°ï¼Œå› æ­¤ â€œ3D é«˜æ–¯å‡½æ•°å¯¹ 3D ä¸­ä»»æ„ç‚¹çš„å½±å“â€ ä¸ â€œæŠ•å½±çš„ 2D é«˜æ–¯å‡½æ•°å¯¹åšä»»æ„åƒç´ ç‚¹çš„å½±å“â€ å…·æœ‰ç›¸åŒçš„å…¬å¼ã€‚å”¯ä¸€çš„åŒºåˆ«æ˜¯å¿…é¡»ä½¿ç”¨æŠ•å½±åˆ° 2D ä¸­å¹³å‡å€¼ Î¼ å’Œåæ–¹å·® Î£ ï¼Œè¿™ä¸€æ­¥ç§°ä¸º EWA splattingâµ ã€‚

å®šä¹‰ç›¸æœºå†…å‚çŸ©é˜µä¸ºKï¼Œå¤–å‚çŸ©é˜µä¸ºW=[R|t]  

2D çš„å‡å€¼ä¸ºï¼š

$$
\mu^{2D} = K((W\mu)/(W\mu)_z)
$$

2Dçš„åæ–¹å·®çŸ©é˜µä¸ºï¼š  

$$
\Sigma^{2D} = JW\Sigma J^\top W^\top
$$

> æ–‡ä¸­æåˆ°ä¸€ç§ç®€åŒ–æ–¹æ³•ï¼Œå¯ä»¥æŠŠåæ–¹å·®çŸ©é˜µä» 3 * 3 ç®€åŒ–ä¸º 2 * 2ã€‚  

```c++
// Forward version of 2D covariance matrix computation
__device__ float3 computeCov2D(
	const float3& mean, // Gaussianä¸­å¿ƒåæ ‡
	float focal_x, // xæ–¹å‘ç„¦è·
	float focal_y, // yæ–¹å‘ç„¦è·
	float tan_fovx,
	float tan_fovy,
	const float* cov3D, // å·²ç»ç®—å‡ºæ¥çš„ä¸‰ç»´åæ–¹å·®çŸ©é˜µ
	const float* viewmatrix) // W2CçŸ©é˜µ
{
	// The following models the steps outlined by equations 29
	// and 31 in "EWA Splatting" (Zwicker et al., 2002). 
	// Additionally considers aspect / scaling of viewport.
	// Transposes used to account for row-/column-major conventions.
	float3 t = transformPoint4x3(mean, viewmatrix);
		// W2CçŸ©é˜µä¹˜Gaussianä¸­å¿ƒåæ ‡å¾—å…¶åœ¨ç›¸æœºåæ ‡ç³»ä¸‹çš„åæ ‡

	const float limx = 1.3f * tan_fovx;
	const float limy = 1.3f * tan_fovy;
	const float txtz = t.x / t.z; // Gaussianä¸­å¿ƒåœ¨åƒå¹³é¢ä¸Šçš„xåæ ‡
	const float tytz = t.y / t.z; // Gaussianä¸­å¿ƒåœ¨åƒå¹³é¢ä¸Šçš„yåæ ‡
	t.x = min(limx, max(-limx, txtz)) * t.z;
	t.y = min(limy, max(-limy, tytz)) * t.z;

	glm::mat3 J = glm::mat3(
		focal_x / t.z, 0.0f, -(focal_x * t.x) / (t.z * t.z),
		0.0f, focal_y / t.z, -(focal_y * t.y) / (t.z * t.z),
		0, 0, 0); // é›…å¯æ¯”çŸ©é˜µï¼ˆç”¨æ³°å‹’å±•å¼€è¿‘ä¼¼ï¼‰

	glm::mat3 W = glm::mat3( // W2CçŸ©é˜µ
		viewmatrix[0], viewmatrix[4], viewmatrix[8],
		viewmatrix[1], viewmatrix[5], viewmatrix[9],
		viewmatrix[2], viewmatrix[6], viewmatrix[10]);

	glm::mat3 T = W * J;

	glm::mat3 Vrk = glm::mat3( // 3Dåæ–¹å·®çŸ©é˜µï¼Œæ˜¯å¯¹ç§°é˜µ
		cov3D[0], cov3D[1], cov3D[2],
		cov3D[1], cov3D[3], cov3D[4],
		cov3D[2], cov3D[4], cov3D[5]);

	glm::mat3 cov = glm::transpose(T) * glm::transpose(Vrk) * T;
		// transpose(J) @ transpose(W) @ Vrk @ W @ J

	// Apply low-pass filter: every Gaussian should be at least
	// one pixel wide/high. Discard 3rd row and column.
	cov[0][0] += 0.3f;
	cov[1][1] += 0.3f;
	return { float(cov[0][0]), float(cov[0][1]), float(cov[1][1]) };
		// åæ–¹å·®çŸ©é˜µæ˜¯å¯¹ç§°çš„ï¼Œåªç”¨å­˜å‚¨ä¸Šä¸‰è§’ï¼Œæ•…åªè¿”å›ä¸‰ä¸ªæ•°
}
```

#### åŠ é€Ÿ

1. å¯¹äºç»™å®šçš„ç›¸æœºï¼Œæ¯ä¸ª 3D ç‚¹çš„ f(p) å¯ä»¥é¢„å…ˆæŠ•å½±åˆ° 2D ä¸­ï¼Œç„¶åå†è¿­ä»£åƒç´ ã€‚é¿å…é‡å¤æŠ•å½±ã€‚
2. æ²¡æœ‰ç½‘ç»œï¼Œä¸éœ€è¦å¯¹å›¾åƒåšé€åƒç´ çš„æ¨ç†ï¼Œ2D é«˜æ–¯åˆ†å¸ƒç›´æ¥æ··åˆåˆ°å›¾åƒä¸Šã€‚
3. å°„çº¿ç»è¿‡å“ªäº› 3D ç‚¹æ˜¯ç¡®å®šçš„ï¼Œä¸éœ€é€‰æ‹©ray samplingç­–ç•¥ã€‚
4. åœ¨ GPU ä¸Šï¼Œä½¿ç”¨å¯å¾®åˆ† CUDA å†…æ ¸çš„è‡ªå®šä¹‰å®ç°ï¼Œæ¯å¸§è¿›è¡Œä¸€æ¬¡é¢„å¤„ç†æ’åºé˜¶æ®µã€‚

> ä½¿ç”¨GPUåŠ é€Ÿä»¥åŠä¸ºæŸäº›æ“ä½œæ·»åŠ è‡ªå®šä¹‰ CUDA å†…æ ¸ï¼ŒåŠ é€Ÿæ¸²æŸ“è¿‡ç¨‹  

##### ç­›é€‰

ç†è®ºä¸Šï¼Œæ¯ä¸ªé«˜æ–¯çƒå¯¹æ‰€æœ‰åƒç´ éƒ½ä¼šæœ‰å½±å“ã€‚ä½†å®é™…ä¸Šï¼Œåœ¨æ¸²æŸ“æŸä¸ªåƒç´ æ—¶ï¼Œä¼šå…ˆè¿‡æ»¤å‡ºç›¸å…³çš„é«˜æ–¯çƒï¼Œå¹¶å¯¹å®ƒä»¬æ’åºï¼ŒæŒ‰ç…§æ·±åº¦é¡ºåºè¿›è¡Œè®¡ç®—ã€‚  

åˆ†ç»„ï¼šä½¿ç”¨ç®€å•çš„ 16x16 åƒç´ å›¾å—å®ç°åˆ†ç»„  
æ’åºï¼šæŒ‰æ·±åº¦å¯¹ 3D ç‚¹è¿›è¡Œæ’åº

![](https://caterpillarstudygroup.github.io/ImportantArticles/assets/7b6ce0e0b104d36e8331f86fd4c9ab5a_3_Figure_3_-1437298192.png)

### é€šè¿‡ 3D é«˜æ–¯è‡ªé€‚åº”å¯†åº¦æ§åˆ¶è¿›è¡Œä¼˜åŒ–

ä¼˜åŒ–å‚æ•°ï¼š
- ä½ç½® ğ‘
> å¯¹positionä½¿ç”¨ç±»ä¼¼äº Plenoxels çš„æ ‡å‡†æŒ‡æ•°è¡°å‡è°ƒåº¦æŠ€æœ¯ã€‚  

- ä¸é€æ˜åº¦ ğ›¼   
> å¯¹ ğ›¼ ä½¿ç”¨ sigmoid æ¿€æ´»å‡½æ•°å°†å…¶é™åˆ¶åœ¨ [0 âˆ’ 1) èŒƒå›´å†…å¹¶è·å¾—å¹³æ»‘æ¢¯åº¦

- åæ–¹å·® Î£  
> **3D é«˜æ–¯åæ–¹å·®å‚æ•°çš„è´¨é‡å¯¹äºè¡¨ç¤ºçš„ç´§å‡‘æ€§è‡³å…³é‡è¦ï¼Œå› ä¸ºå¯ä»¥ç”¨å°‘é‡å¤§çš„å„å‘å¼‚æ€§é«˜æ–¯å‡½æ•°æ•è·å¤§çš„å‡åŒ€åŒºåŸŸã€‚**  
> å‡ºäºç±»ä¼¼çš„åŸå› ï¼Œå¯¹åæ–¹å·®å°ºåº¦ä½¿ç”¨æŒ‡æ•°æ¿€æ´»å‡½æ•°ã€‚

- é¢œè‰² ğ‘ çš„ SH ç³»æ•°ï¼Œæˆ–è€…é¢œè‰²

**è¿™äº›å‚æ•°çš„ä¼˜åŒ–ä¸æ§åˆ¶é«˜æ–¯å¯†åº¦çš„æ­¥éª¤äº¤ç»‡åœ¨ä¸€èµ·**ï¼Œä»¥æ›´å¥½åœ°è¡¨ç¤ºåœºæ™¯ã€‚

#### åˆå§‹åŒ–

åˆå§‹åŒ–æ˜¯æŒ‡åœ¨è®­ç»ƒå¼€å§‹æ—¶è®¾ç½®çš„ 3D ç‚¹çš„å‚æ•°ã€‚  

å¯¹äº**ç‚¹ä½ç½®ï¼ˆå‡å€¼ï¼‰**ï¼Œä½œè€…å»ºè®®ä½¿ç”¨ç”± SfMï¼ˆè¿åŠ¨ç»“æ„ï¼‰ç”Ÿæˆçš„ç‚¹äº‘ã€‚å› ä¸ºå¯¹äºä»»ä½• 3D é‡å»ºï¼Œæ— è®ºæ˜¯ä½¿ç”¨ GSã€NeRF è¿˜æ˜¯æ›´ç»å…¸çš„æ–¹æ³•ï¼Œéƒ½å¿…é¡»çŸ¥é“ç›¸æœºçŸ©é˜µï¼Œå› æ­¤éƒ½ä¼šéœ€è¦è¿è¡Œ SfM æ¥â€‹â€‹è·å–è¿™äº›çŸ©é˜µã€‚SfM ä¼šäº§ç”Ÿç¨€ç–ç‚¹äº‘ä½œä¸ºå‰¯äº§å“ï¼Œä¸ºä»€ä¹ˆä¸å°†å…¶ç”¨äºåˆå§‹åŒ–å‘¢ï¼Ÿå½“ç”±äºæŸç§åŸå› æ— æ³•è·å¾—ç‚¹äº‘æ—¶ï¼Œå¯ä»¥ä½¿ç”¨éšæœºåˆå§‹åŒ–ï¼Œä½†å¯èƒ½ä¼šæŸå¤±æœ€ç»ˆé‡å»ºè´¨é‡ã€‚  
**åæ–¹å·®**è¢«åˆå§‹åŒ–ä¸ºå„å‘åŒæ€§ï¼Œå³åŠå¾„ä¸º ä»çƒä½“meanå¼€å§‹åˆ°ç›¸é‚»ç‚¹çš„å¹³å‡è·ç¦»ï¼Œè¿™æ · 3D ä¸–ç•Œå°±å¯ä»¥è¢«å¾ˆå¥½åœ°è¦†ç›–ï¼Œæ²¡æœ‰â€œæ´â€ã€‚

```python
def create_from_pcd(self, pcd : BasicPointCloud, spatial_lr_scale : float):
    self.spatial_lr_scale = spatial_lr_scale
    # ä½ç½®åˆå§‹åŒ–
    fused_point_cloud = torch.tensor(np.asarray(pcd.points)).float().cuda()
    # é¢œè‰²åˆå§‹åŒ–
    fused_color = RGB2SH(torch.tensor(np.asarray(pcd.colors)).float().cuda())
    features = torch.zeros((fused_color.shape[0], 3, (self.max_sh_degree + 1) ** 2)).float().cuda()
    features[:, :3, 0 ] = fused_color
    features[:, 3:, 1:] = 0.0

    print("Number of points at initialisation : ", fused_point_cloud.shape[0])
    # åæ–¹å·®scaleåˆå§‹åŒ–
    dist2 = torch.clamp_min(distCUDA2(torch.from_numpy(np.asarray(pcd.points)).float().cuda()), 0.0000001)
    scales = torch.log(torch.sqrt(dist2))[...,None].repeat(1, 3)
    # åæ–¹æ³•rotationåˆå§‹åŒ–
    rots = torch.zeros((fused_point_cloud.shape[0], 4), device="cuda")
    rots[:, 0] = 1
    # ä¸é€æ˜åº¦åˆå§‹åŒ–
    opacities = inverse_sigmoid(0.1 * torch.ones((fused_point_cloud.shape[0], 1), dtype=torch.float, device="cuda"))

    self._xyz = nn.Parameter(fused_point_cloud.requires_grad_(True))
    self._features_dc = nn.Parameter(features[:,:,0:1].transpose(1, 2).contiguous().requires_grad_(True))
    self._features_rest = nn.Parameter(features[:,:,1:].transpose(1, 2).contiguous().requires_grad_(True))
    self._scaling = nn.Parameter(scales.requires_grad_(True))
    self._rotation = nn.Parameter(rots.requires_grad_(True))
    self._opacity = nn.Parameter(opacities.requires_grad_(True))
    self.max_radii2D = torch.zeros((self.get_xyz.shape[0]), device="cuda")
```
#### ä¼˜åŒ–

1. åœ°é¢çœŸå®è§†å›¾å’Œå½“å‰æ¸²æŸ“ä¹‹é—´çš„ L1 Loss

```python
def l1_loss(network_output, gt):
    return torch.abs((network_output - gt)).mean()
```

2. D-SSIMï¼šç»“æ„å·®å¼‚æŒ‡æ•°æµ‹é‡

```python
def _ssim(img1, img2, window, window_size, channel, size_average=True):
    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)
    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)

    mu1_sq = mu1.pow(2)
    mu2_sq = mu2.pow(2)
    mu1_mu2 = mu1 * mu2

    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq
    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq
    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2

    C1 = 0.01 ** 2
    C2 = 0.03 ** 2

    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))

    if size_average:
        return ssim_map.mean()
    else:
        return ssim_map.mean(1).mean(1).mean(1)
```
#### é«˜æ–¯è‡ªé€‚åº”æ§åˆ¶

ç›®çš„ï¼šè§£å†³é‡å»ºä¸è¶³å’Œè¿‡åº¦é‡å»ºçš„é—®é¢˜  
åŸå› ï¼šSGD æœ¬èº«åªèƒ½è°ƒæ•´ç°æœ‰çš„ç‚¹ã€‚ä½†åœ¨å®Œå…¨æ²¡æœ‰ç‚¹ï¼ˆé‡å»ºä¸è¶³ï¼‰æˆ–ç‚¹å¤ªå¤šï¼ˆè¿‡åº¦é‡å»ºï¼‰çš„åŒºåŸŸä¸­ï¼Œå®ƒå¾ˆéš¾æ‰¾åˆ°å¥½çš„å‚æ•°ã€‚è¿™æ—¶å°±éœ€è¦è‡ªé€‚åº”è‡´å¯†åŒ–ã€‚  
é¢‘ç‡ï¼šåœ¨è®­ç»ƒæœŸé—´å¶å°”å¯åŠ¨ä¸€æ¬¡ï¼Œæ¯”å¦‚æ¯ 100 ä¸ª SGD æ­¥  
æ–¹æ³•ï¼šï¼Œåˆ†å‰²å…·æœ‰å¤§æ¢¯åº¦çš„ç‚¹ï¼ˆå›¾ 8ï¼‰å¹¶åˆ é™¤å·²ç»æ”¶æ•›åˆ°éå¸¸ä½çš„ Î± å€¼çš„ç‚¹ï¼ˆå¦‚æœä¸€ä¸ªç‚¹æ˜¯å¦‚æ­¤é€æ˜ï¼Œä¸ºä»€ä¹ˆè¦ä¿ç•™å®ƒï¼Ÿï¼‰ã€‚

![](./assets/90c87fe420b7f068f6ef682c1ee5ed26_5_Figure_4_1909201227.png)

å…·ä½“ç­–ç•¥ä¸ºï¼š  

1. å½“æ£€æµ‹åˆ°è§†å›¾ç©ºé—´ä½ç½®æ¢¯åº¦è¾ƒå¤§æ—¶ï¼Œå¢åŠ é«˜æ–¯å¯†åº¦

>å¯¹äºé‡å»ºä¸è¶³æˆ–è¿‡åº¦é‡å»ºï¼Œè¿™ä¸¤è€…éƒ½æœ‰å¾ˆå¤§çš„è§†å›¾ç©ºé—´ä½ç½®æ¢¯åº¦ã€‚ç›´è§‚ä¸Šï¼Œè¿™å¯èƒ½æ˜¯å› ä¸ºå®ƒä»¬å¯¹åº”äºå°šæœªå¾ˆå¥½é‡å»ºçš„åŒºåŸŸï¼Œå¹¶ä¸”ä¼˜åŒ–å°è¯•ç§»åŠ¨é«˜æ–¯æ¥çº æ­£è¿™ä¸€ç‚¹ã€‚

2. å¯¹äºé‡å»ºåŒºåŸŸä¸­çš„å°é«˜æ–¯ï¼Œå¦‚æœéœ€è¦åˆ›å»ºçš„æ–°çš„å‡ ä½•å½¢çŠ¶ï¼Œæœ€å¥½é€šè¿‡ç®€å•åœ°åˆ›å»ºç›¸åŒå¤§å°çš„å‰¯æœ¬å¹¶å°†å…¶æ²¿ä½ç½®æ¢¯åº¦çš„æ–¹å‘ç§»åŠ¨æ¥å…‹éš†é«˜æ–¯ã€‚

```python
def densify_and_clone(self, grads, grad_threshold, scene_extent):
    # Extract points that satisfy the gradient condition
    selected_pts_mask = torch.where(torch.norm(grads, dim=-1) >= grad_threshold, True, False)
    selected_pts_mask = torch.logical_and(selected_pts_mask,
                                            torch.max(self.get_scaling, dim=1).values <= self.percent_dense*scene_extent)
    # æå–å‡ºå¤§äºé˜ˆå€¼`grad_threshold`ä¸”ç¼©æ”¾å‚æ•°è¾ƒå°ï¼ˆå°äºself.percent_dense * scene_extentï¼‰çš„Gaussiansï¼Œåœ¨ä¸‹é¢è¿›è¡Œå…‹éš†
    
    new_xyz = self._xyz[selected_pts_mask]
    new_features_dc = self._features_dc[selected_pts_mask]
    new_features_rest = self._features_rest[selected_pts_mask]
    new_opacities = self._opacity[selected_pts_mask]
    new_scaling = self._scaling[selected_pts_mask]
    new_rotation = self._rotation[selected_pts_mask]

    self.densification_postfix(new_xyz, new_features_dc, new_features_rest, new_opacities, new_scaling, new_rotation)
```

3. æœ‰é«˜æ–¹å·®çš„åŒºåŸŸä¸­çš„å¤§é«˜æ–¯éœ€è¦è¢«åˆ†å‰²æˆæ›´å°çš„é«˜æ–¯ã€‚æˆ‘ä»¬ç”¨ä¸¤ä¸ªæ–°çš„é«˜æ–¯å‡½æ•°æ›¿æ¢è¿™äº›é«˜æ–¯å‡½æ•°ï¼Œå¹¶å°†å®ƒä»¬çš„å°ºåº¦é™¤ä»¥æˆ‘ä»¬é€šè¿‡å®éªŒç¡®å®šçš„å› å­ ğœ™ = 1.6ã€‚æˆ‘ä»¬è¿˜é€šè¿‡ä½¿ç”¨åŸå§‹ 3D é«˜æ–¯ä½œä¸º PDF è¿›è¡Œé‡‡æ ·æ¥åˆå§‹åŒ–å®ƒä»¬çš„ä½ç½®ã€‚

> å…‹éš†é«˜æ–¯ä¸åˆ†å‰²é«˜æ–¯çš„åŒºåˆ«åœ¨äºï¼Œå‰è€…ä¼šå¢åŠ ç³»ç»Ÿæ€»ä½“ç§¯å’Œé«˜æ–¯æ•°é‡ï¼Œè€Œåè€…åœ¨ä¿ç•™æ€»ä½“ç§¯ä½†å¢åŠ é«˜æ–¯æ•°é‡ã€‚

```python
def densify_and_split(self, grads, grad_threshold, scene_extent, N=2):
    n_init_points = self.get_xyz.shape[0]
    # Extract points that satisfy the gradient condition
    padded_grad = torch.zeros((n_init_points), device="cuda")
    padded_grad[:grads.shape[0]] = grads.squeeze()
    selected_pts_mask = torch.where(padded_grad >= grad_threshold, True, False)
    selected_pts_mask = torch.logical_and(selected_pts_mask,
                                            torch.max(self.get_scaling, dim=1).values > self.percent_dense*scene_extent)
    '''
    è¢«åˆ†è£‚çš„Gaussiansæ»¡è¶³ä¸¤ä¸ªæ¡ä»¶ï¼š
    1. ï¼ˆå¹³å‡ï¼‰æ¢¯åº¦è¿‡å¤§ï¼›
    2. åœ¨æŸä¸ªæ–¹å‘çš„æœ€å¤§ç¼©æ”¾å¤§äºä¸€ä¸ªé˜ˆå€¼ã€‚
    å‚ç…§è®ºæ–‡5.2èŠ‚â€œOn the other hand...â€ä¸€æ®µï¼Œå¤§Gaussianè¢«åˆ†è£‚æˆä¸¤ä¸ªå°Gaussiansï¼Œ
    å…¶æ”¾ç¼©è¢«é™¤ä»¥Ï†=1.6ï¼Œä¸”ä½ç½®æ˜¯ä»¥åŸå…ˆçš„å¤§Gaussianä½œä¸ºæ¦‚ç‡å¯†åº¦å‡½æ•°è¿›è¡Œé‡‡æ ·çš„ã€‚
    '''

    stds = self.get_scaling[selected_pts_mask].repeat(N,1)
    means = torch.zeros((stds.size(0), 3),device="cuda")
    samples = torch.normal(mean=means, std=stds)
    rots = build_rotation(self._rotation[selected_pts_mask]).repeat(N,1,1)
    new_xyz = torch.bmm(rots, samples.unsqueeze(-1)).squeeze(-1) + self.get_xyz[selected_pts_mask].repeat(N, 1)
    # ç®—å‡ºéšæœºé‡‡æ ·å‡ºæ¥çš„æ–°åæ ‡
    # bmm: batch matrix-matrix product
    new_scaling = self.scaling_inverse_activation(self.get_scaling[selected_pts_mask].repeat(N,1) / (0.8*N))
    new_rotation = self._rotation[selected_pts_mask].repeat(N,1)
    new_features_dc = self._features_dc[selected_pts_mask].repeat(N,1,1)
    new_features_rest = self._features_rest[selected_pts_mask].repeat(N,1,1)
    new_opacity = self._opacity[selected_pts_mask].repeat(N,1)

    self.densification_postfix(new_xyz, new_features_dc, new_features_rest, new_opacity, new_scaling, new_rotation)

    prune_filter = torch.cat((selected_pts_mask, torch.zeros(N * selected_pts_mask.sum(), device="cuda", dtype=bool)))
    self.prune_points(prune_filter)
```

6. ä¸å…¶ä»–ä½“ç§¯è¡¨ç¤ºç±»ä¼¼ï¼Œä¼˜åŒ–ç»“æœå¯èƒ½è¢«é è¿‘æ‘„åƒæœºçš„æµ®åŠ¨ä½“çš„å¹²æ‰°ã€‚åœ¨é«˜æ–¯æ²‰æµ¸ä¸­ï¼Œè¿™ç§å¹²æ‰°ä¼šå¯¼è‡´é«˜æ–¯å¯†åº¦çš„ä¸åˆç†å¢åŠ ã€‚  
ç¼“å’Œé«˜æ–¯æ•°é‡å¢åŠ çš„æœ‰æ•ˆæ–¹æ³•æ˜¯:  
(1) æ¯éš” ğ‘ = 3000 è¿­ä»£å°† ğ›¼ å€¼è®¾ç½®ä¸ºæ¥è¿‘äºé›¶ã€‚ç„¶åï¼Œä¼˜åŒ–ä¼šåœ¨éœ€è¦æ—¶å¢åŠ é«˜æ–¯å‡½æ•°çš„ ğ›¼ï¼ŒåŒæ—¶åˆ é™¤ ğ›¼ å°äº ğœ–ğ›¼ çš„é«˜æ–¯å‡½æ•°ï¼Œå¦‚ä¸Šæ‰€è¿°ã€‚é«˜æ–¯å¯èƒ½ä¼šç¼©å°æˆ–å¢é•¿ï¼Œå¹¶ä¸”ä¸å…¶ä»–é«˜æ–¯æœ‰ç›¸å½“å¤§çš„é‡å   
(2) å®šæœŸåˆ é™¤é€æ˜çš„æˆ–è€…éå¸¸å¤§çš„é«˜æ–¯ã€‚  
è¯¥ç­–ç•¥å¯ä»¥æ€»ä½“ä¸Šå¾ˆå¥½åœ°æ§åˆ¶é«˜æ–¯æ€»æ•°ã€‚

```python
# æ¥ä¸‹æ¥ç§»é™¤ä¸€äº›Gaussiansï¼Œå®ƒä»¬æ»¡è¶³ä¸‹åˆ—è¦æ±‚ä¸­çš„ä¸€ä¸ªï¼š
# 1. æ¥è¿‘é€æ˜ï¼ˆä¸é€æ˜åº¦å°äºmin_opacityï¼‰
# 2. åœ¨æŸä¸ªç›¸æœºè§†é‡é‡Œå‡ºç°è¿‡çš„æœ€å¤§2DåŠå¾„å¤§äºå±å¹•ï¼ˆåƒå¹³é¢ï¼‰å¤§å°
# 3. åœ¨æŸä¸ªæ–¹å‘çš„æœ€å¤§ç¼©æ”¾å¤§äº0.1 * extentï¼ˆä¹Ÿå°±æ˜¯è¯´å¾ˆé•¿çš„é•¿æ¡å½¢ä¹Ÿæ˜¯ä¼šè¢«ç§»é™¤çš„ï¼‰
prune_mask = (self.get_opacity < min_opacity).squeeze()
if max_screen_size:
    big_points_vs = self.max_radii2D > max_screen_size # vs = view space?
    big_points_ws = self.get_scaling.max(dim=1).values > 0.1 * extent
    prune_mask = torch.logical_or(torch.logical_or(prune_mask, big_points_vs), big_points_ws) # ws = world space?
self.prune_points(prune_mask)
```

### é«˜æ–¯å¿«é€Ÿå¯å¾®å…‰æ …åŒ–å™¨

ç›®æ ‡ï¼š  
å¯¹æ‰€æœ‰é«˜æ–¯è¿›è¡Œå¿«é€Ÿæ•´ä½“æ¸²æŸ“ã€å¿«é€Ÿæ’åºï¼Œè¿‘ä¼¼ ğ›¼ æ··åˆï¼ˆåŒ…æ‹¬å„å‘å¼‚æ€§ splatï¼‰ï¼Œè€Œä¸éœ€è¦é™åˆ¶é«˜æ–¯çš„æ•°é‡ã€‚

æœ¬æ–‡ä¸ºé«˜æ–¯å›¾è®¾è®¡äº†ä¸€ä¸ªåŸºäºå›¾å—çš„å…‰æ …åŒ–å™¨ï¼Œå…¶ç‰¹ç‚¹ä¸ºï¼š  
1. ä¸€æ¬¡å¯¹æ•´ä¸ªå›¾åƒçš„åŸºå…ƒè¿›è¡Œé¢„æ’åº
2. å…è®¸åœ¨ä»»æ„æ•°é‡çš„æ··åˆé«˜æ–¯ä¸Šè¿›è¡Œæœ‰æ•ˆçš„åå‘ä¼ æ’­ï¼Œå¹¶ä¸”ï¼ˆå…‰æ …åŒ–å™¨çš„ï¼‰é™„åŠ å†…å­˜æ¶ˆè€—ä½ï¼Œæ¯ä¸ªåƒç´ åªéœ€è¦æ’å®šçš„å¼€é”€ã€‚
3. å…‰æ …åŒ–pipelineæ˜¯å®Œå…¨å¯å¾®åˆ†çš„
4. è€ƒè™‘åˆ° 2D æŠ•å½±ï¼ˆç¬¬ 4 èŠ‚ï¼‰ï¼Œå…‰æ …åŒ–å™¨å¯ä»¥å¯¹å„å‘å¼‚æ€§ splats è¿›è¡Œå…‰æ …åŒ–ã€‚

å…·ä½“æ­¥éª¤ä¸ºï¼š  
1. å°†å±å¹•åˆ†å‰²æˆ 16Ã—16 å—
2. æ ¹æ®è§†é”¥ä½“å’Œæ¯ä¸ªå—å‰”é™¤ 3D é«˜æ–¯ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åªä¿ç•™ä¸è§†é”¥ä½“ç›¸äº¤çš„ç½®ä¿¡åŒºé—´ä¸º 99% çš„é«˜æ–¯åˆ†å¸ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¿æŠ¤å¸¦æ¥ç®€å•åœ°æ‹’ç»æç«¯ä½ç½®å¤„çš„é«˜æ–¯åˆ†å¸ƒï¼ˆå³é‚£äº›å‡å€¼æ¥è¿‘è¿‘å¹³é¢ä¸”è¿œç¦»è§†é”¥ä½“çš„ä½ç½®ï¼‰ï¼Œå› ä¸ºå®ƒä»¬çš„**æŠ•å½± 2D åæ–¹å·®å°†ä¸ç¨³å®š**ã€‚
3. æ ¹æ®æ¯ä¸ªé«˜æ–¯é‡å çš„å›¾å—æ•°é‡æ¥å®ä¾‹åŒ–å®ƒä»¬ï¼Œå¹¶ä¸ºæ¯ä¸ªå®ä¾‹åˆ†é…ä¸€ä¸ªç»“åˆäº†è§†å›¾ç©ºé—´æ·±åº¦å’Œå›¾å— ID çš„é”®ã€‚
4. ä½¿ç”¨å•ä¸ªå¿«é€Ÿ GPU åŸºæ•°æ’åºæ ¹æ®è¿™äº›é”®å¯¹é«˜æ–¯è¿›è¡Œæ’åº [Merrill å’Œ Grimshaw 2010]ã€‚è¯·æ³¨æ„ï¼Œ**æ²¡æœ‰é¢å¤–çš„æ¯åƒç´ ç‚¹æ’åºï¼Œæ··åˆæ˜¯åŸºäºæ­¤åˆå§‹æ’åºæ‰§è¡Œçš„**ã€‚å› æ­¤ï¼Œ ğ›¼ æ··åˆåœ¨æŸäº›æƒ…å†µä¸‹å¯èƒ½æ˜¯è¿‘ä¼¼çš„ã€‚ç„¶è€Œï¼Œå½“å›¾å—æ¥è¿‘å•ä¸ªåƒç´ çš„å¤§å°æ—¶ï¼Œè¿™äº›è¿‘ä¼¼å€¼å˜å¾—å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚æˆ‘ä»¬å‘ç°è¿™ç§æ–¹å¼**æå¤§åœ°å¢å¼ºäº†è®­ç»ƒå’Œæ¸²æŸ“æ€§èƒ½ï¼Œè€Œä¸ä¼šåœ¨èåˆåœºæ™¯ä¸­äº§ç”Ÿå¯è§çš„ä¼ªå½±**ã€‚
5. é€šè¿‡è¯†åˆ«æ’åºåæ·±åº¦æœ€å¤§å’Œæœ€å°çš„é«˜æ–¯æ¥ä¸ºæ¯ä¸ªå›¾å—ç”Ÿæˆä¸€ä¸ªåˆ—è¡¨ã€‚
6. å¯¹äºå…‰æ …åŒ–ï¼Œæˆ‘ä»¬ä¸ºæ¯ä¸ªå›¾å—å¯åŠ¨ä¸€ä¸ªçº¿ç¨‹å—ã€‚æ¯ä¸ªçº¿ç¨‹ï¼š  
ï¼ˆ1ï¼‰é¦–å…ˆåä½œåœ°å°†é«˜æ–¯æ•°æ®åŒ…åŠ è½½åˆ°å…±äº«å†…å­˜ä¸­ã€‚  
ï¼ˆ2ï¼‰ç„¶åå¯¹äºç»™å®šçš„åƒç´ ï¼Œé€šè¿‡ä»å‰åˆ°åéå†åˆ—è¡¨æ¥ç´¯ç§¯é¢œè‰²å’Œğ›¼å€¼ï¼Œä»è€Œæœ€å¤§åŒ–æ•°æ®åŠ è½½/å…±äº«å’Œå¤„ç†çš„å¹¶è¡Œæ€§å¢ç›Šã€‚  
ï¼ˆ3ï¼‰å½“æˆ‘ä»¬è¾¾åˆ°åƒç´ ä¸­çš„ç›®æ ‡é¥±å’Œåº¦ ğ›¼ æ—¶ï¼Œç›¸åº”çš„çº¿ç¨‹å°±ä¼šåœæ­¢ã€‚  
æ¯éš”ä¸€æ®µæ—¶é—´ï¼Œå°±ä¼šæŸ¥è¯¢å›¾å—ä¸­çš„çº¿ç¨‹ï¼Œå¹¶ä¸”å½“æ‰€æœ‰åƒç´ éƒ½é¥±å’Œæ—¶ï¼ˆå³ ğ›¼ å˜ä¸º 1ï¼‰ï¼Œæ•´ä¸ªå›¾å—çš„å¤„ç†å°±ä¼šç»ˆæ­¢ã€‚

> é™„å½• C ä¸­ç»™å‡ºäº†æ’åºçš„è¯¦ç»†ä¿¡æ¯å’Œæ€»ä½“å…‰æ …åŒ–æ–¹æ³•çš„é«˜çº§æ¦‚è¿°ã€‚

## å®ç°

### è®­ç»ƒ

```python
def training(dataset, opt, pipe, testing_iterations, saving_iterations, checkpoint_iterations, checkpoint, debug_from):
    first_iter = 0
    tb_writer = prepare_output_and_logger(dataset)
    gaussians = GaussianModel(dataset.sh_degree)
    scene = Scene(dataset, gaussians)
    gaussians.training_setup(opt)
    if checkpoint:
        (model_params, first_iter) = torch.load(checkpoint)
        gaussians.restore(model_params, opt)

    bg_color = [1, 1, 1] if dataset.white_background else [0, 0, 0]
    background = torch.tensor(bg_color, dtype=torch.float32, device="cuda")

    iter_start = torch.cuda.Event(enable_timing = True)
    iter_end = torch.cuda.Event(enable_timing = True)

    viewpoint_stack = None
    ema_loss_for_log = 0.0
    progress_bar = tqdm(range(first_iter, opt.iterations), desc="Training progress")
    first_iter += 1
    for iteration in range(first_iter, opt.iterations + 1):        
        iter_start.record()

        gaussians.update_learning_rate(iteration)

        # Every 1000 its we increase the levels of SH up to a maximum degree
        if iteration % 1000 == 0:
            gaussians.oneupSHdegree()

        # Pick a random Camera
        if not viewpoint_stack:
            viewpoint_stack = scene.getTrainCameras().copy()
        viewpoint_cam = viewpoint_stack.pop(randint(0, len(viewpoint_stack)-1))

        # Render
        if (iteration - 1) == debug_from:
            pipe.debug = True

        bg = torch.rand((3), device="cuda") if opt.random_background else background

        render_pkg = render(viewpoint_cam, gaussians, pipe, bg)
        image, viewspace_point_tensor, visibility_filter, radii = render_pkg["render"], render_pkg["viewspace_points"], render_pkg["visibility_filter"], render_pkg["radii"]

        # Loss
        gt_image = viewpoint_cam.original_image.cuda()
        Ll1 = l1_loss(image, gt_image)
        loss = (1.0 - opt.lambda_dssim) * Ll1 + opt.lambda_dssim * (1.0 - ssim(image, gt_image))
        loss.backward()

        iter_end.record()

        with torch.no_grad():
            # Log and save
            training_report(tb_writer, iteration, Ll1, loss, l1_loss, iter_start.elapsed_time(iter_end), testing_iterations, scene, render, (pipe, background))
            if (iteration in saving_iterations):
                print("\n[ITER {}] Saving Gaussians".format(iteration))
                scene.save(iteration)

            # Densification
            if iteration < opt.densify_until_iter:
                # Keep track of max radii in image-space for pruning
                gaussians.max_radii2D[visibility_filter] = torch.max(gaussians.max_radii2D[visibility_filter], radii[visibility_filter])
                gaussians.add_densification_stats(viewspace_point_tensor, visibility_filter)

                if iteration > opt.densify_from_iter and iteration % opt.densification_interval == 0:
                    size_threshold = 20 if iteration > opt.opacity_reset_interval else None
                    gaussians.densify_and_prune(opt.densify_grad_threshold, 0.005, scene.cameras_extent, size_threshold)
                
                if iteration % opt.opacity_reset_interval == 0 or (dataset.white_background and iteration == opt.densify_from_iter):
                    gaussians.reset_opacity()

            # Optimizer step
            if iteration < opt.iterations:
                gaussians.optimizer.step()
                gaussians.optimizer.zero_grad(set_to_none = True)

            if (iteration in checkpoint_iterations):
                print("\n[ITER {}] Saving Checkpoint".format(iteration))
                torch.save((gaussians.capture(), iteration), scene.model_path + "/chkpnt" + str(iteration) + ".pth")
```

### æ¨æ–­

#### ç›¸æœº

3Dæ˜¯åœ¨ä¸–ç•Œåæ ‡ç³»ä¸‹æ„å»ºçš„ï¼Œè®¾ç½®å¥½ç›¸æœºçš„å†…å‚å’Œå¤–å‚åï¼Œéœ€è¦æŠŠæ‰€æœ‰ä¸–ç•Œåæ ‡ç³»ä¸‹çš„æ•°æ®è½¬æ¢åˆ°ç›¸æœºåæ ‡ç³»ä¸‹ï¼Œå¹¶ä¸”æŠ•å½±åˆ°å±å¹•ä¸Šã€‚  

ä»¥ä¸‹æ˜¯æ ¹æ®ç›¸æœºçš„å†…å‚å¤–å‚è®¡ç®—åæ ‡ç³»è½¬æ¢çŸ©é˜µå’ŒæŠ•å½±çŸ©é˜µçš„è¿‡ç¨‹ã€‚  

```python
class Camera(nn.Module):
    def __init__(self, colmap_id, R, T, FoVx, FoVy, image, gt_alpha_mask,
                 image_name, uid,
                 trans=np.array([0.0, 0.0, 0.0]), scale=1.0, data_device = "cuda"
                 ):
        super(Camera, self).__init__()

        self.uid = uid
        self.colmap_id = colmap_id
        self.R = R # ç›¸æœºåœ¨ä¸–ç•Œåæ ‡ç³»ä¸‹çš„æ—‹è½¬çŸ©é˜µ
        self.T = T # ç›¸æœºåœ¨ç›¸æœºåæ ‡ç³»ä¸‹çš„ä½ç½®ã€‚ï¼ˆç›¸æœºåæ ‡ç³»çš„åŸç‚¹ä¸ä¸–ç•Œåæ ‡ç³»ç›¸åŒï¼Œåªæ˜¯ç›¸å·®äº†ä¸€ä¸ªæ—‹è½¬ï¼‰
        self.FoVx = FoVx # xæ–¹å‘è§†åœºè§’
        self.FoVy = FoVy # yæ–¹å‘è§†åœºè§’
        self.image_name = image_name

        try:
            self.data_device = torch.device(data_device)
        except Exception as e:
            print(e)
            print(f"[Warning] Custom device {data_device} failed, fallback to default cuda device" )
            self.data_device = torch.device("cuda")

        self.original_image = image.clamp(0.0, 1.0).to(self.data_device) # åŸå§‹å›¾åƒ
        self.image_width = self.original_image.shape[2] # å›¾åƒå®½åº¦
        self.image_height = self.original_image.shape[1] # å›¾åƒé«˜åº¦

        if gt_alpha_mask is not None:
            self.original_image *= gt_alpha_mask.to(self.data_device)
        else:
            self.original_image *= torch.ones((1, self.image_height, self.image_width), device=self.data_device)

		# è·ç¦»ç›¸æœºå¹³é¢znearå’Œzfarä¹‹é—´ä¸”åœ¨è§†é”¥å†…çš„ç‰©ä½“æ‰ä¼šè¢«æ¸²æŸ“
        self.zfar = 100.0 # æœ€è¿œèƒ½çœ‹åˆ°å¤šè¿œ
        self.znear = 0.01 # æœ€è¿‘èƒ½çœ‹åˆ°å¤šè¿‘

        self.trans = trans # ç›¸æœºä¸­å¿ƒçš„å¹³ç§»
        self.scale = scale # ç›¸æœºä¸­å¿ƒåæ ‡çš„ç¼©æ”¾

        # world_2_camera = [[R,T],[0,1]]ï¼Œworld_view_transformæ˜¯world_2_cameraçš„è½¬ç½®
        self.world_view_transform = torch.tensor(getWorld2View2(R, T, trans, scale)).transpose(0, 1).cuda() # ä¸–ç•Œåˆ°ç›¸æœºåæ ‡ç³»çš„å˜æ¢çŸ©é˜µï¼Œ4Ã—4
        # projection matrixçš„å®šä¹‰è§ï¼š
        # https://caterpillarstudygroup.github.io/GAMES101_mdbook/MVP/OrthographicProjection.html
        # https://caterpillarstudygroup.github.io/GAMES101_mdbook/MVP/PerspectiveProjection.html
        # æ­¤å¤„çš„projection_matrixä¹Ÿæ˜¯çœŸå®projection matrixçš„è½¬ç½®
        self.projection_matrix = getProjectionMatrix(znear=self.znear, zfar=self.zfar, fovX=self.FoVx, fovY=self.FoVy).transpose(0,1).cuda() # æŠ•å½±çŸ©é˜µ
        # æ­£ç¡®çš„è®¡ç®—å…¬å¼ä¸ºï¼šmvp = projection * world_2_camera
        # ä½†full_proj_transformæ˜¯mvpçš„è½¬ç½®ï¼Œæ‰€ä»¥æ˜¯world_view_transform * projection_matrix
        self.full_proj_transform = (self.world_view_transform.unsqueeze(0).bmm(self.projection_matrix.unsqueeze(0))).squeeze(0) # ä»ä¸–ç•Œåæ ‡ç³»åˆ°å›¾åƒçš„å˜æ¢çŸ©é˜µ
        # ä¸Šé¢çš„Tæ˜¯ç›¸æœºåœ¨ç›¸æœºåæ ‡ç³»ä¸‹çš„ä½ç½®ï¼Œæ­¤å¤„çš„camera centeræ˜¯ç›¸æœºåœ¨ä¸–ç•Œåæ ‡ç³»ä¸‹çš„ä½ç½®ã€‚
        self.camera_center = self.world_view_transform.inverse()[3, :3] # ç›¸æœºåœ¨ä¸–ç•Œåæ ‡ç³»ä¸‹çš„åæ ‡
```

#### pythonæ¸²æŸ“æ¥å£
**viewmatrixå’Œprojmatrixéƒ½å¿…é¡»ä¼ å…¥åŸå§‹çŸ©é˜µçš„é€†çŸ©é˜µï¼Œå› æ­¤pythonçš„çŸ©é˜µå­˜å‚¨æ˜¯è¡Œä¼˜åŒ–çš„ï¼ŒC++çš„çŸ©é˜µå­˜å‚¨æ˜¯åˆ—ä¼˜å…ˆçš„ã€‚æ‰€ä»¥åŒæ—¶çš„çŸ©é˜µå†…å­˜æ•°æ®ï¼Œåœ¨pythoné‡Œå’Œåœ¨c++é‡Œæ˜¯äº’é€†çš„å…³ç³»ã€‚**

```python
def render(viewpoint_camera, pc : GaussianModel, pipe, bg_color : torch.Tensor, scaling_modifier = 1.0, override_color = None):
    """
    Render the scene. 
    viewpoint_camera: FOVï¼Œç”»å¸ƒå¤§å°ã€ç›¸æœºä½ç½®ã€å˜æ¢çŸ©é˜µ
    pc: ç”¨äºè·å–é«˜æ–¯çƒçš„å±æ€§
    pipeï¼šä¸€äº›é…ç½®
    Background tensor (bg_color) must be on GPU!
    """
 
    # Create zero tensor. We will use it to make pytorch return gradients of the 2D (screen-space) means
    screenspace_points = torch.zeros_like(pc.get_xyz, dtype=pc.get_xyz.dtype, requires_grad=True, device="cuda") + 0
    try:
        screenspace_points.retain_grad()
    except:
        pass

    # Set up rasterization configuration
    tanfovx = math.tan(viewpoint_camera.FoVx * 0.5)
    tanfovy = math.tan(viewpoint_camera.FoVy * 0.5)

    raster_settings = GaussianRasterizationSettings(
        image_height=int(viewpoint_camera.image_height),
        image_width=int(viewpoint_camera.image_width),
        tanfovx=tanfovx,
        tanfovy=tanfovy,
        bg=bg_color,
        scale_modifier=scaling_modifier,
        viewmatrix=viewpoint_camera.world_view_transform, # world to camera
        projmatrix=viewpoint_camera.full_proj_transform, # mvp
        sh_degree=pc.active_sh_degree,
        campos=viewpoint_camera.camera_center, # camera position
        prefiltered=False,
        debug=pipe.debug
    )

    rasterizer = GaussianRasterizer(raster_settings=raster_settings)

    means3D = pc.get_xyz 
    means2D = screenspace_points
    opacity = pc.get_opacity

    # If precomputed 3d covariance is provided, use it. If not, then it will be computed from
    # scaling / rotation by the rasterizer.
    scales = None
    rotations = None
    cov3D_precomp = None
    if pipe.compute_cov3D_python:
        cov3D_precomp = pc.get_covariance(scaling_modifier)
    else:
        scales = pc.get_scaling
        rotations = pc.get_rotation

    # If precomputed colors are provided, use them. Otherwise, if it is desired to precompute colors
    # from SHs in Python, do it. If not, then SH -> RGB conversion will be done by rasterizer.
    shs = None
    colors_precomp = None
    # æ²¡æœ‰é¢„åˆ¶çš„colorï¼Œå°±è®¡ç®—è¿‡color
    if override_color is None:
        # å¦‚æœé¢„æµ‹çš„æ˜¯SHçš„ç³»æ•°ï¼Œåˆ™æ ¹æ®SHè®¡ç®—color
        if pipe.convert_SHs_python:
            shs_view = pc.get_features.transpose(1, 2).view(-1, 3, (pc.max_sh_degree+1)**2)
            dir_pp = (pc.get_xyz - viewpoint_camera.camera_center.repeat(pc.get_features.shape[0], 1))
            dir_pp_normalized = dir_pp/dir_pp.norm(dim=1, keepdim=True)
            sh2rgb = eval_sh(pc.active_sh_degree, shs_view, dir_pp_normalized)
            colors_precomp = torch.clamp_min(sh2rgb + 0.5, 0.0)
        # æˆ–è€…ç›´æ¥é¢„æµ‹color
        else:
            shs = pc.get_features
    else:
        colors_precomp = override_color

    # Rasterize visible Gaussians to image, obtain their radii (on screen). 
    rendered_image, radii = rasterizer(
        means3D = means3D,
        means2D = means2D,
        shs = shs,
        colors_precomp = colors_precomp,
        opacities = opacity,
        scales = scales,
        rotations = rotations,
        cov3D_precomp = cov3D_precomp)

    # Those Gaussians that were frustum culled or had a radius of 0 were not visible.
    # They will be excluded from value updates used in the splitting criteria.
    return {"render": rendered_image,
            "viewspace_points": screenspace_points,
            "visibility_filter" : radii > 0,
            "radii": radii}
```

#### C++æ¸²æŸ“æ¥å£

![](./assets/a72cc63a000e41da8c749d562dcdd030.png)

```c++
// Forward rendering procedure for differentiable rasterization
// of Gaussians.
int CudaRasterizer::Rasterizer::forward(
	std::function<char* (size_t)> geometryBuffer,
	std::function<char* (size_t)> binningBuffer,
	std::function<char* (size_t)> imageBuffer,
	/*
		ä¸Šé¢çš„ä¸‰ä¸ªå‚æ•°æ˜¯ç”¨äºåˆ†é…ç¼“å†²åŒºçš„å‡½æ•°ï¼Œ
		åœ¨submodules/diff-gaussian-rasterization/rasterize_points.cuä¸­å®šä¹‰
	*/
	const int P, // Gaussiançš„æ•°é‡
	int D, // å¯¹åº”äºGaussianModel.active_sh_degreeï¼Œæ˜¯çƒè°åº¦æ•°ï¼ˆæœ¬æ–‡å‚è€ƒçš„å­¦ä¹ ç¬”è®°åœ¨è¿™é‡Œæ˜¯é”™è¯¯çš„ï¼‰
	int M, // RGBä¸‰é€šé“çš„çƒè°å‚…é‡Œå¶ç³»æ•°ä¸ªæ•°ï¼Œåº”ç­‰äº3 Ã— (D + 1)Â²ï¼ˆæœ¬æ–‡å‚è€ƒçš„å­¦ä¹ ç¬”è®°åœ¨è¿™é‡Œä¹Ÿæ˜¯é”™è¯¯çš„ï¼‰
	const float* background,
	const int width, int height, // å›¾ç‰‡å®½é«˜
	const float* means3D, // Gaussiansçš„ä¸­å¿ƒåæ ‡
	const float* shs, // çƒè°ç³»æ•°
	const float* colors_precomp, // é¢„å…ˆè®¡ç®—çš„RGBé¢œè‰²
	const float* opacities, // ä¸é€æ˜åº¦
	const float* scales, // ç¼©æ”¾
	const float scale_modifier, // ç¼©æ”¾çš„ä¿®æ­£é¡¹
	const float* rotations, // æ—‹è½¬
	const float* cov3D_precomp, // é¢„å…ˆè®¡ç®—çš„3ç»´åæ–¹å·®çŸ©é˜µ
	const float* viewmatrix, // W2CçŸ©é˜µ
	const float* projmatrix, // æŠ•å½±çŸ©é˜µ
	const float* cam_pos, // ç›¸æœºåæ ‡
	const float tan_fovx, float tan_fovy, // è§†åœºè§’ä¸€åŠçš„æ­£åˆ‡å€¼
	const bool prefiltered,
	float* out_color, // è¾“å‡ºçš„é¢œè‰²
	int* radii, // å„Gaussianåœ¨åƒå¹³é¢ä¸Šç”¨3ÏƒåŸåˆ™æˆªå–åçš„åŠå¾„
	bool debug)
{
	const float focal_y = height / (2.0f * tan_fovy); // yæ–¹å‘çš„ç„¦è·
	const float focal_x = width / (2.0f * tan_fovx); // xæ–¹å‘çš„ç„¦è·
	/*
		æ³¨æ„tan_fov = tan(fov / 2) ï¼ˆè§ä¸Šé¢çš„renderå‡½æ•°ï¼‰ã€‚
		è€Œtan(fov / 2)å°±æ˜¯å›¾åƒå®½/é«˜çš„ä¸€åŠä¸ç„¦è·ä¹‹æ¯”ã€‚
		ä»¥xæ–¹å‘ä¸ºä¾‹ï¼Œtan(fovx / 2) = width / 2 / focal_xï¼Œ
		æ•…focal_x = width / (2 * tan(fovx / 2)) = width / (2 * tan_fovx)ã€‚
	*/

	// ä¸‹é¢åˆå§‹åŒ–ä¸€äº›ç¼“å†²åŒº
	size_t chunk_size = required<GeometryState>(P); // GeometryStateå æ®ç©ºé—´çš„å¤§å°
	char* chunkptr = geometryBuffer(chunk_size);
	GeometryState geomState = GeometryState::fromChunk(chunkptr, P);

	if (radii == nullptr)
	{
		radii = geomState.internal_radii;
	}

	dim3 tile_grid((width + BLOCK_X - 1) / BLOCK_X, (height + BLOCK_Y - 1) / BLOCK_Y, 1);
		// BLOCK_X = BLOCK_Y = 16ï¼Œå‡†å¤‡åˆ†è§£æˆ16Ã—16çš„tilesã€‚
		// ä¹‹æ‰€ä»¥ä¸èƒ½åˆ†è§£æˆæ›´å¤§çš„tilesï¼Œæ˜¯å› ä¸ºå¯¹äºåŒä¸€å¼ å›¾ç‰‡çš„ç¦»å¾—è¾ƒè¿œçš„åƒç´ ç‚¹è€Œè¨€
		// GaussianæŒ‰æ·±åº¦æ’åºçš„ç»“æœå¯èƒ½æ˜¯ä¸åŒçš„ã€‚
		// ï¼ˆæƒ³è±¡ä¸€ä¸‹ä¸¤ä¸ªGaussiansç¦»åƒå¹³é¢å¾ˆè¿‘ï¼Œä¸€ä¸ªé è¿‘å›¾åƒå·¦è¾¹ç¼˜ï¼Œä¸€ä¸ªé è¿‘å³è¾¹ç¼˜ï¼‰
		// dim3æ˜¯CUDAå®šä¹‰çš„å«ä¹‰x,y,zä¸‰ä¸ªæˆå‘˜çš„ä¸‰ç»´unsigned intå‘é‡ç±»ã€‚
		// tile_gridå°±æ˜¯xå’Œyæ–¹å‘ä¸Štileçš„ä¸ªæ•°ã€‚
	dim3 block(BLOCK_X, BLOCK_Y, 1);

	// Dynamically resize image-based auxiliary buffers during training
	size_t img_chunk_size = required<ImageState>(width * height);
	char* img_chunkptr = imageBuffer(img_chunk_size);
	ImageState imgState = ImageState::fromChunk(img_chunkptr, width * height);

	if (NUM_CHANNELS != 3 && colors_precomp == nullptr)
	{
		throw std::runtime_error("For non-RGB, provide precomputed Gaussian colors!");
	}

	// Run preprocessing per-Gaussian (transformation, bounding, conversion of SHs to RGB)
	CHECK_CUDA(FORWARD::preprocess(
		P, D, M,
		means3D,
		(glm::vec3*)scales,
		scale_modifier,
		(glm::vec4*)rotations,
		opacities,
		shs,
		geomState.clamped,
		cov3D_precomp,
		colors_precomp,
		viewmatrix, projmatrix,
		(glm::vec3*)cam_pos,
		width, height,
		focal_x, focal_y,
		tan_fovx, tan_fovy,
		radii,
		geomState.means2D, // GaussianæŠ•å½±åˆ°åƒå¹³é¢ä¸Šçš„ä¸­å¿ƒåæ ‡
		geomState.depths, // Gaussiançš„æ·±åº¦
		geomState.cov3D, // ä¸‰ç»´åæ–¹å·®çŸ©é˜µ
		geomState.rgb, // é¢œè‰²
		geomState.conic_opacity, // æ¤­åœ†äºŒæ¬¡å‹çš„çŸ©é˜µå’Œä¸é€æ˜åº¦çš„æ‰“åŒ…å‘é‡
		tile_grid, // 
		geomState.tiles_touched,
		prefiltered
	), debug) // é¢„å¤„ç†ï¼Œä¸»è¦æ¶‰åŠæŠŠ3Dçš„GaussianæŠ•å½±åˆ°2D

	// Compute prefix sum over full list of touched tile counts by Gaussians
	// E.g., [2, 3, 0, 2, 1] -> [2, 5, 5, 7, 8]
	CHECK_CUDA(cub::DeviceScan::InclusiveSum(geomState.scanning_space, geomState.scan_size, geomState.tiles_touched, geomState.point_offsets, P), debug)
		// è¿™æ­¥æ˜¯ä¸ºduplicateWithKeysåšå‡†å¤‡
		// ï¼ˆè®¡ç®—å‡ºæ¯ä¸ªGaussianå¯¹åº”çš„keyså’Œvaluesåœ¨æ•°ç»„ä¸­å­˜å‚¨çš„èµ·å§‹ä½ç½®ï¼‰

	// Retrieve total number of Gaussian instances to launch and resize aux buffers
	int num_rendered;
	CHECK_CUDA(cudaMemcpy(&num_rendered, geomState.point_offsets + P - 1, sizeof(int), cudaMemcpyDeviceToHost), debug); // ä¸œè¥¿å¡åˆ°GPUé‡Œé¢å»

	size_t binning_chunk_size = required<BinningState>(num_rendered);
	char* binning_chunkptr = binningBuffer(binning_chunk_size);
	BinningState binningState = BinningState::fromChunk(binning_chunkptr, num_rendered);

	// For each instance to be rendered, produce adequate [ tile | depth ] key 
	// and corresponding dublicated Gaussian indices to be sorted
	duplicateWithKeys << <(P + 255) / 256, 256 >> > (
		P,
		geomState.means2D,
		geomState.depths,
		geomState.point_offsets,
		binningState.point_list_keys_unsorted,
		binningState.point_list_unsorted,
		radii,
		tile_grid) // ç”Ÿæˆæ’åºæ‰€ç”¨çš„keyså’Œvalues
	CHECK_CUDA(, debug)

	int bit = getHigherMsb(tile_grid.x * tile_grid.y);

	// Sort complete list of (duplicated) Gaussian indices by keys
	CHECK_CUDA(cub::DeviceRadixSort::SortPairs(
		binningState.list_sorting_space,
		binningState.sorting_size,
		binningState.point_list_keys_unsorted, binningState.point_list_keys,
		binningState.point_list_unsorted, binningState.point_list,
		num_rendered, 0, 32 + bit), debug)
		// è¿›è¡Œæ’åºï¼ŒæŒ‰keysæ’åºï¼šæ¯ä¸ªtileå¯¹åº”çš„GaussiansæŒ‰æ·±åº¦æ”¾åœ¨ä¸€èµ·ï¼›valueæ˜¯Gaussiançš„ID

	CHECK_CUDA(cudaMemset(imgState.ranges, 0, tile_grid.x * tile_grid.y * sizeof(uint2)), debug);

	// Identify start and end of per-tile workloads in sorted list
	if (num_rendered > 0)
		identifyTileRanges << <(num_rendered + 255) / 256, 256 >> > (
			num_rendered,
			binningState.point_list_keys,
			imgState.ranges); // è®¡ç®—æ¯ä¸ªtileå¯¹åº”æ’åºè¿‡çš„æ•°ç»„ä¸­çš„å“ªä¸€éƒ¨åˆ†
	CHECK_CUDA(, debug)

	// Let each tile blend its range of Gaussians independently in parallel
	const float* feature_ptr = colors_precomp != nullptr ? colors_precomp : geomState.rgb;
	CHECK_CUDA(FORWARD::render(
		tile_grid, block, // block: æ¯ä¸ªtileçš„å¤§å°
		imgState.ranges,
		binningState.point_list,
		width, height,
		geomState.means2D,
		feature_ptr,
		geomState.conic_opacity,
		imgState.accum_alpha,
		imgState.n_contrib,
		background,
		out_color), debug) // æœ€åï¼Œè¿›è¡Œæ¸²æŸ“

	return num_rendered;
}

```
## æœ‰æ•ˆ

## å±€é™æ€§

1. åœ¨è§†è§’ä¸å¯è§åŒºåŸŸæœ‰ä¼ªå½±ã€‚è§£å†³æ–¹æ³•ï¼šé€šè¿‡è§„åˆ™å‰”é™¤è¿™äº›ä¼ªå½±ã€‚  
2. ç®€å•çš„å¯è§æ€§ç®—æ³•ï¼Œå¯èƒ½å¯¼è‡´é«˜æ–¯çªç„¶åˆ‡æ¢æ·±åº¦/æ··åˆé¡ºåºã€‚è§£å†³æ–¹æ³•ï¼šå¯ä»¥é€šè¿‡æŠ—é”¯é½¿æ¥è§£å†³ã€‚  
3. æ²¡æœ‰å¯¹æˆ‘ä»¬çš„ä¼˜åŒ–åº”ç”¨ä»»ä½•æ­£åˆ™åŒ–ï¼›è§£å†³æ–¹æ³•ï¼šåŠ å…¥æ­£åˆ™åŒ–å°†æœ‰åŠ©äºå¤„ç†çœ‹ä¸è§çš„åŒºåŸŸå’Œå¼¹å‡ºçš„ä¼ªå½±ã€‚
4. ä¸€æ¬¡åªèƒ½æ¸²æŸ“ä¸€å¼ å›¾åƒï¼Œä¸èƒ½æ‰¹é‡è¿›è¡Œã€‚

## éªŒè¯

## å¯å‘

## é—ç•™é—®é¢˜

## å‚è€ƒææ–™

1. https://towardsdatascience.com/a-comprehensive-overview-of-gaussian-splatting-e7d570081362
2. https://caterpillarstudygroup.github.io/ImportantArticles/3D_Gaussian_Splatting.html
3. æºç è§£è¯»ï¼šhttps://blog.csdn.net/qaqwqaqwq/article/details/136837906