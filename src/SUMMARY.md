# Summary

[ReadPapers]()

- [Introduction](README.md)
- [Implicit Warping for Animation with Image Sets](53.md)
- [Mix-of-Show: Decentralized Low-Rank Adaptation for Multi-Concept Customization of Diffusion Models](52.md)
- [Motion-Conditioned Diffusion Model for Controllable Video Synthesis](51.md)
- [Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets](50.md)
- [UniAnimate: Taming Unified Video Diffusion Models for Consistent Human Image Animation](49.md)
- [Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models](48.md)
- [Puppet-Master: Scaling Interactive Video Generation as a Motion Prior for Part-Level Dynamics](47.md)
- [A Recipe for Scaling up Text-to-Video Generation](46.md)
- [High-Resolution Image Synthesis with Latent Diffusion Models](45.md)
- [Motion-I2V: Consistent and Controllable Image-to-Video Generation with Explicit Motion Modeling](44.md)
- [数据集：HumanVid](43.md)
- [HumanVid: Demystifying Training Data for Camera-controllable Human Image Animation](42.md)
- [StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation](41.md)
- [数据集：Zoo-300K](40.md)
- [Motion Avatar: Generate Human and Animal Avatars with Arbitrary Motion](39.md)
- [LORA: LOW-RANK ADAPTATION OF LARGE LAN-GUAGE MODELS](38.md)
- [TCAN: Animating Human Images with Temporally Consistent Pose Guidance using Diffusion Models](37.md)
- [GaussianAvatar: Towards Realistic Human Avatar Modeling from a Single Video via Animatable 3D Gaussians](36.md)
- [MagicPony: Learning Articulated 3D Animals in the Wild](35.md)
- [Splatter a Video: Video Gaussian Representation for Versatile Processing](34.md)
- [数据集：Dynamic Furry Animal Dataset](33.md)
- [Artemis: Articulated Neural Pets with Appearance and Motion Synthesis](32.md)
- [SMPLer: Taming Transformers for Monocular 3D Human Shape and Pose Estimation](31.md)
- [CAT3D: Create Anything in 3D with Multi-View Diffusion Models](30.md)
- [PACER+: On-Demand Pedestrian Animation Controller in Driving Scenarios](29.md)
- [Humans in 4D: Reconstructing and Tracking Humans with Transformers](28.md)
- [Learning Human Motion from Monocular Videos via Cross-Modal Manifold Alignment](27.md)
- [PhysPT: Physics-aware Pretrained Transformer for Estimating Human Dynamics from Monocular Videos](26.md)
- [Imagic: Text-Based Real Image Editing with Diffusion Models](25.md)
- [DiffEdit: Diffusion-based semantic image editing with mask guidance](24.md)
- [Dual diffusion implicit bridges for image-to-image translation](23.md)
- [SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations](22.md)
-[InstructPix2Pix: Learning to Follow Image Editing Instructions](21.md)
- [Prompt-to-Prompt Image Editing with Cross-Attention Control](20.md)
- [WANDR: Intention-guided Human Motion Generation](19.md)
- [TRAM: Global Trajectory and Motion of 3D Humans from in-the-wild Videos](18.md)
- [3D Gaussian Splatting for Real-Time Radiance Field Rendering](17.md)
- [Decoupling Human and Camera Motion from Videos in the Wild](16.md)
- [HMP: Hand Motion Priors for Pose and Shape Estimation from Video](15.md)
- [HuMoR: 3D Human Motion Model for Robust Pose Estimation](14.md)
- [Co-Evolution of Pose and Mesh for 3D Human Body Estimation from Video](13.md)
- [Global-to-Local Modeling for Video-based 3D Human Pose and Shape Estimation](12.md)
- [WHAM: Reconstructing World-grounded Humans with Accurate 3D Motion](11.md)
- [Tackling the Generative Learning Trilemma with Denoising Diffusion GANs](10.md)
- [Elucidating the Design Space of Diffusion-Based Generative Models](9.md)
- [SCORE-BASED GENERATIVE MODELING THROUGHSTOCHASTIC DIFFERENTIAL EQUATIONS](8.md)
- [Consistency Models](7.md)
- [Classifier-Free Diffusion Guidance](6.md)
- [Cascaded Diffusion Models for High Fidelity Image Generation](5.md)
- [LEARNING ENERGY-BASED MODELS BY DIFFUSIONRECOVERY LIKELIHOOD](4.md)
- [On Distillation of Guided Diffusion Models](3.md)
- [Denoising Diffusion Implicit Models](2.md)
- [PROGRESSIVE DISTILLATION FOR FAST SAMPLING OF DIFFUSION MODELS](./1.md)

