# Think Before You Diffuse: LLMs-Guided Physics-Aware Video Generation

## 研究背景与问题

### 要解决的问题

实现物理正确且照片级真实的视频生成。

### 现在有方法及其问题

1. 现有视频扩散模型在生成视觉上吸引人的视频方面表现优异。便难以直接从海量数据中学习这些复杂的物理规律。因此在生成视频中合成正确、符合物理规律的效果方面存在困难，尤其是在处理复杂的现实世界运动、物体间相互作用和动力学时。
2. 通过神经网络从视觉输入中提取物理表示，用于下游的推理或模拟。尽管这些方法在图形学、机器人和科学计算等领域有效，但它们通常依赖于基于规则的手工求解器，这限制了其表达能力和可扩展性，并且需要大量的手动调整。此外，它们通常局限于合成数据，无法扩展到复杂的、真实世界的视频生成。

### 本文方法及优势

1. 利用LLM进行物理推理，显式地分析用户提供的文本提示，并生成一个全面的物理上下文，详细描述文本提示中隐含或涉及的物理规律（如重力、碰撞、流体、材料属性等）。
2. 将LLM推理出的物理上下文信息注入到扩散模型（即视频生成模型）中，指导其生成过程。
3. 利用MLLM监督与训练目标 
4. 构建了一个新的高质量物理视频数据集，该数据集包含多样化的物理动作和事件

## 主要方法

[TODO] 图2

给定用户提示:
1. 利用预训练的大型语言模型 (LLM) 从文本输入中推理物理属性。
2. (a) 利用物理语境增强用户提示，并 (b) 生成一个与所描述事件相关的物理现象清单。
3. 使用增强后的提示来指导视频生成。同时，物理现象清单被用来惩罚包含不合理物理现象的输出。

### 将文本描述锚定于物理语境

利用预训练的 LLM 来推理物理语境，并获取三种类型的文本描述：
(1) 一个物理属性清单，用于捕捉角色（起因/结果）、相互作用和物理规律；
(2) 一个包含场景和物理细节的增强提示；
(3) 一个与事件相关的物理现象清单。

#### 物理属性推理

使用思维链 (Chain-of-Thought, CoT) [54] 提示技术来引导一个预训练的大型语言模型:  
(1) 识别所涉及的关键物理原理；
(2) 确定哪些实体发起动作，哪些实体受到影响；
(3) 推理这些实体如何相互作用；
(4) 记录任何由此产生的物理现象。
最终，获得一个既全面又有效的物理属性清单。

#### 增强文本提示

基于提取出的物理属性，提示 LLM “生动地描述场景，包括物体、动作和氛围”。不仅捕捉了场景的力学方面，还捕捉了其叙事深度。  
允许 LLM 通过引入新的实体（产生外力）以保证逻辑一致性。

#### 物理现象

生成一个与目标事件相关联的『物理现象』清单。其中『物理现象』是由事件状态变化引起的事实。  
这些『物理现象』清单用于指导训练过程。当事实被满足时，可以奖励扩散模型；当事实缺失或错误时，则可以惩罚它。

