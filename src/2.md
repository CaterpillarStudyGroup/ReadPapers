# 核心问题是什么？

DDPM的特点是require simulating a Markov chain for many steps in order to produce a sample，生成速度太慢。

# 核心贡献是什么？

DDIM，快速地生成且生成结果是确定的。由于生成结果是确定的，可用于latent space插值、编辑等任务。

# 大致方法

We show that the resulting variational training objectives have a shared surrogate objective, which is exactly the objective used to train DDPM. Therefore, we can freely choose from a large family of generative models using the same neural network simply by choosing a different, nonMarkovian diffusion process (Section 4.1) and the corresponding reverse generative Markov Chain. In particular, we are able to use non-Markovian diffusion processes which lead to "short" generative Markov chains (Section 4.2) that can be simulated in a small number of steps. This can massively increase sample efficiency only at a minor cost in sample quality.

# 有效性

DDIMs相比于DDPMs的优越性：

1.  DDIMs have superior sample generation quality compared to DDPMs, when we accelerate sampling by 10× to100× using our proposed method.&#x20;
2.  DDIM samples have the following "consistency" property, which does not hold for DDPMs: if we start with the same initial latent variable and generate several samples with Markov chains of various lengths, these samples would have similar high-level features.&#x20;
3.  because of "consistency" in DDIMs, we can perform semantically meaningful image interpolation by manipulating the initial latent variable in DDIMs, unlike DDPMs which interpolates near the image space due to the stochastic generative process.

# 缺陷

# 验证

# 启发

# 遗留问题

1.  为什么说DDIM的过程是non-Markovian的？
2.  为什么DDIM需要少量的steps?
