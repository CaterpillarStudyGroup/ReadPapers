## DiffEdit: Diffusion-based semantic image editing with mask guidance     

### 任务目标

> SDEdit要求用户对想更新的区域打MASK。  

Instead of asking users to provide the mask, the model will generate the mask itself based on the caption and query.    


![](assets/D2-21.png) 


> &#x2705; 作者认为让用户打 MASK 比较麻烦，因此生成 MASK    


P22   
### Pipeline

![](assets/D2-22.png)  

> &#x2705; Step 1：对原始图像加噪分别根据两个文本，Q 和 R 对加噪结果去噪。对两个去噪结果求差，得出哪些区域应该被重新生成。    
> &#x2705; Step 2：用 DDIM 对原始图像编码，得到 noise.    
> &#x2705; 注意：step 1 的加高斯噪声与 step 2 的 DDIM Encoding 不同。前者是非确定的，后者是确定的。    
> &#x2705; Step 3：DDIM Decoding，但对于非 MASK 区域，用 Step 2 相同 step 的对应值覆盖。    

P23   
### 效果
![](assets/D2-23.png)      

> 生成质量高且与原始相似度高。  
