# SMPLer: Taming Transformers for Monocular 3D Human Shape and Pose Estimation

## 核心问题是什么?

### 目的

单目 3D 人体形状和姿势估计

### 现有方法及存在的问题

现有的的 Transformer 通常具有O(l^2)的计算和存储复杂度，l为特征长度。  
这阻碍了对高分辨率特征中细粒度信息的利用，但高分辨率特征对于精确重建很重要。

### 本文方法

我们提出了一个基于 SMPL 的 Transformer 框架（SMPLer）来解决这个问题。 SMPLer 包含两个关键要素：**解耦的注意力操作**和**基于 SMPL 的目标表示**，这允许有效利用 Transformer 中的**高分辨率特征**。  
此外，基于这两种设计，我们还引入了几个新颖的模块，包括**多尺度注意力**和**联合感知注意力**，以进一步提高重建性能。  

### 效果

大量实验在定量和定性方面证明了 SMPLer 对现有 3D 人体形状和姿势估计方法的有效性。值得注意的是，所提出的算法在 Human3.6M 数据集上实现了 45.2 mm 的 MPJPE，比 Mesh Graphomer 提高了 10% 以上，参数减少了不到三分之一。代码和预训练模型可在 https://github.com/xuxy09/SMPLer 获取。

## 核心贡献是什么？

1.  **解耦注意力机制（Decoupled Attention）**：为了解决传统Transformer在处理高分辨率特征时面临的二次计算和内存复杂度问题，论文提出了一种解耦的注意力操作，将完整的注意力操作分解为目标-特征注意力和目标-目标注意力，从而降低了计算和内存复杂度。

2.  **基于SMPL的目标表示（SMPL-based Target Representation）**：论文引入了基于SMPL（Skinned Multi-Person Linear model）的参数化人体模型作为目标表示，这大大减少了目标嵌入的长度，降低了计算和内存成本，同时保证了生成的3D人体网格的平滑性和一致性。

3.  **多尺度注意力（Multi-scale Attention）**：通过结合不同分辨率的特征图，并为每个尺度分配不同的投影权重，论文提出的多尺度注意力机制能够更有效地利用多尺度信息进行3D人体姿态和形状估计。

4.  **关节感知注意力（Joint-aware Attention）**：利用基于SMPL的目标表示，论文设计了一种关节感知的注意力模块，该模块专注于人体关节周围的局部特征，以更好地推断3D人体的姿态。

5.  **分层架构（Hierarchical Architecture）**：为了解决关节感知注意力依赖于2D关节估计的问题，论文提出了一种分层架构，通过多个Transformer块逐步细化2D关节估计和3D重建结果。

6.  **实验验证**：论文通过大量实验验证了SMPLer相对于现有3D人体姿态和形状估计方法的有效性，特别是在Human3.6M数据集上，与Mesh Graphormer相比，参数数量减少到原来的三分之一，而MPJPE（Mean Per Joint Position Error）降低了10%以上。

7.  **实时推理速度**：SMPLer在保持高效率的同时，能够实现实时的推理速度，这对于实际应用如虚拟现实和增强现实等场景非常重要。

8.  **虚拟角色控制**：由于SMPLer能够直接输出3D旋转，因此它可以方便地用于控制虚拟角色，这一点在元宇宙等应用中具有潜在价值。

9.  **代码和预训练模型的可用性**：论文提供了代码和预训练模型，这为研究人员和开发者进一步研究和应用该框架提供了便利。

## 大致方法是什么？

## 训练与验证

### 数据集

### loss

### 训练策略

## 有效

## 缺陷

## 启发

## 遗留问题

## 参考材料