# Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding

## 1. **核心技术与架构**
Imagen 是由 Google 提出的基于扩散模型（Diffusion Model）的文本到图像生成模型，其核心创新在于结合了大型预训练语言模型（如 T5）的文本理解能力与扩散模型的高保真图像生成能力。模型架构主要包括以下部分：
- **冻结的文本编码器**：采用 T5-XXL（4.6B 参数）等大规模语言模型，将输入文本编码为语义嵌入向量。研究发现，**单纯增大语言模型规模比增大图像扩散模型更能显著提升生成质量**。
- **级联扩散模型**：分为三级生成流程：
  1. **基础模型**：生成 64×64 分辨率的初始图像；
  2. **超分辨率模型**：将图像逐步提升至 256×256 和 1024×1024 分辨率。每级模型均基于改进的 U-Net 架构，并通过跨模态注意力机制融合文本嵌入。
- **动态阈值采样（Dynamic Thresholding）**：允许使用更大的引导权重（Classifier-Free Guidance），避免像素过饱和，从而提升图像真实感与文本对齐效果。

## 2. **关键创新点**
- **语言模型的跨模态应用**：首次验证**纯文本预训练的大语言模型（如 T5）可直接用于图像生成任务，且其性能远超传统图文对齐模型（如 CLIP）**。这一发现颠覆了视觉-语言任务需依赖多模态联合训练的认知。
- **高效的 U-Net 优化**：通过调整残差块数量、下采样顺序及注意力机制，显著提升模型收敛速度与内存效率。例如，在低分辨率层增加残差块并调整跳跃连接权重，使训练速度提升 2-3 倍。
- **级联生成与噪声调节**：通过分阶段生成高分辨率图像并结合噪声调节增强技术，确保生成过程的稳定性和细节保真度。

## 主要方法

Improved DDPM + UNet

## 3. **评估与实验结果**
- **DrawBench 基准**：提出包含 200 个复杂文本提示的评估框架，涵盖组合性、空间关系、罕见词理解等维度。人类评估显示，Imagen 在图像质量和文本对齐上显著优于 DALL-E 2、GLIDE 等模型。
- **定量指标**：在 COCO 数据集上，Imagen 的零样本 FID 得分达 6.66，优于同期主流模型。
- **生成示例**：展示了对复杂文本（如“宇航员骑马的油画”）的高保真生成能力，细节处理优于 DALL-E 2。

## 4. **局限性及未来方向**
- **计算成本**：级联扩散模型需多阶段生成，对算力要求较高；
- **多样性限制**：同一文本多次生成可能输出相似图像，需改进随机性策略；
- **社会偏见**：依赖大规模网络数据训练的模型可能继承语言模型的社会偏见。

## 启发

1. 单纯增大语言模型规模比增大图像扩散模型更能显著提升生成质量
2. 纯文本预训练的大语言模型（如 T5）可直接用于图像生成任务，且其性能远超传统图文对齐模型（如 CLIP）
